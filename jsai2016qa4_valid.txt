 when a neural net solves for y-x-x , does it require learning how multiplication and polynomials work , or are multiplication and polynomials pre-trained via the structure of a neural network ? : machinelearning from a practical perspective , can a neural net solve for y-x2 without the use of sigmoid y-mx-b functions being [ pre-learned and ] used at some or all of nodes ? EOQ i have it that it just cuts off all parts of the big equation an ann is until there's mostly only x-x left . basically an ann is that : a huge equation that twists and bends itself until it's close enough to one that solves the problem . EOA 
 when a neural net solves for y-x-x , does it require learning how multiplication and polynomials work , or are multiplication and polynomials pre-trained via the structure of a neural network ? : machinelearning from a practical perspective , can a neural net solve for y-x2 without the use of sigmoid y-mx-b functions being [ pre-learned and ] used at some or all of nodes ? EOQ it can do addition directly , multiplication is approximated EOA 
 non-machine learning entrepreneur looking to buy a coffee or drink for an expert in nyc and learn about your passions . : machinelearning register yourself at a meetup . there are few in ny . EOQ need it be nyc ? we could skype ... EOA 
 non-machine learning entrepreneur looking to buy a coffee or drink for an expert in nyc and learn about your passions . : machinelearning register yourself at a meetup . there are few in ny . EOQ i suppose not , but can't buy a drink over skype...yet. may i contact you directly to set up a quick chat ? EOA 
 non-machine learning entrepreneur looking to buy a coffee or drink for an expert in nyc and learn about your passions . : machinelearning register yourself at a meetup . there are few in ny . EOQ an expert ? try offering a great dinner , due to both the time required and the value of the expertise . EOA 
 non-machine learning entrepreneur looking to buy a coffee or drink for an expert in nyc and learn about your passions . : machinelearning register yourself at a meetup . there are few in ny . EOQ fair enough . pick a place ! EOA 
 non-machine learning entrepreneur looking to buy a coffee or drink for an expert in nyc and learn about your passions . : machinelearning register yourself at a meetup . there are few in ny . EOQ i'm no expert...yet... maybe in a couple of years lol . EOA 
 non-machine learning entrepreneur looking to buy a coffee or drink for an expert in nyc and learn about your passions . : machinelearning register yourself at a meetup . there are few in ny . EOQ maybe the meal should be commensurate with expertise ? that said , i'd like to avoid the seinfeld situation where kenny bania orders a soup and it doesn't count as a meal....this might get complicated .... EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ i will have NUM gb of ram if i go with the NUM x or NUM gb of ram if i go with dual xeons . i will use one or two pcei-e ssds along with regular ssds for long term storage . i may do other work besides just neural nets , although that is the primarily reason for the build . there are other applications in machine learning that don't utilize gpus . i am wondering how much of a benefit would xeons be in those situtations . going the xeon route with ecc ram would cost me about $5k more , but i will have more ram so i can be lazier with my coding . EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ the cpu and ssd are used for data loading in gpu deep learning . if you want to do other cpu heavy training or processing i don't see a reason to do it on your gpu machine. if you train a random forrest on your gpu machine you'll slow down training . buy two machines if you need cpu and gpu power but for different purposes . EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ save those pcie lanes for the gpus EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ i am going to be using the asus x99 e ws so it will be able to handle it . EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ it's not about the slots . it's about the lanes . the cpu gives NUM . the motherboard can't change that . with NUM gpus you don't want to waste any on ssds EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ i believe the NUM x only supports NUM gb of ram . even so , this will be enough seeing as you will probably have NUM gb of vram but leave less room for lazy coding . i am looking into a new rig as well and am considering going the xeon route for the extra ram . EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ x99 and therefore NUM x support only NUM pci-e lanes . you will not get full NUM x pci-e bandwidth to NUM cards with that . i think this will end up being a bottleneck in most cases because you are moving data in and out of the gpu memory all the time . EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ i read even x8 doesn't bottle neck the gpu . i will be using the asus x99 e ws if i go with the NUM x , so i can use more pcie devices . EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ in gaming context ? game rendering does not require massive throughput between gpu and ram because textures are massively reused when rendering NUM d scenes . with machine learning computation you are constantly shuffling data and models between gpus and ram . it's a different story . i don't have any numbers to back this up though . make sure you understand the difference between pci-e slot and pci-e lane . EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ NUM gpus ? probably going to need to invest a shitton in fans rather than debate between cpus . probably won't even scale well past NUM gpus . EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ i will be water cooling . i know not all programs allow to use multiple gpus , but the ones that do i will benefit from . if i run the ones that don't . i can just run different training sets on each . EOA 
 xeon vs NUM x ? : machinelearning you don't need the most powerful processor to do deep learning with NUM gpus , i've seen a single i7 work fine for NUM titan xs as long as you don't do a dramatic amount of cpu preprocessing of images . i will however say that having an excellent ssd is very important if your dataset doesn't fit in memory , a pci express ssd has NUM x the performance of a sata NUM ssd . EOQ pick the one with the higher cpu clock speed ( probably the NUM x ) EOA 
 thoughts on : feature extraction : foundations and applications ? : machinelearning i think it is too expensive to buy . the book is a collections of papers describing results of a benchmark that took place in NUM . it may be outdated . with NUM $ , you can buy two or three good and updated books about machine learning . EOQ if you like something from the toc , just search for the authors' papers . EOA 
 iteration process of constructing a dnn : machinelearning while a bit of an oversimplification , the answer here is that these parameters are often learned . these parameters aren't learned via backprop ( as the network parameters are ) but are chosen using cross validation . check out this blog post for an intro . URL EOQ but cross validation depending on the size of the network can be too expensive , no? for example on imagenet , do they use cross validation to select the entire architecture ? i think it can be used to select between a few options , not many parameters like i cited . also i guess they began doing experiments with small networks . EOA 
 iteration process of constructing a dnn : machinelearning while a bit of an oversimplification , the answer here is that these parameters are often learned . these parameters aren't learned via backprop ( as the network parameters are ) but are chosen using cross validation . check out this blog post for an intro . URL EOQ yes , it is very expensive. this is one reason why many big companies win machine learning contests , because they can afford to do lots of cross validation as they have many gpus . it sounds like you might be more interested in rules of thumb for designing networks . the best advice i can give is to look at other networks that have been successful at similar tasks trained by folks who have the resources to do massive cross validations . a good example is dropout ( though this is falling out of favor-batch normalization seems to diminish the need for this ) . i usually use dropout as a regularizer and simply set it to .5. is that the right value ? almost assuredly not . does is work ? usually, yeah . EOA 
 iteration process of constructing a dnn : machinelearning while a bit of an oversimplification , the answer here is that these parameters are often learned . these parameters aren't learned via backprop ( as the network parameters are ) but are chosen using cross validation . check out this blog post for an intro . URL EOQ thanks for the advice ! EOA 
 iteration process of constructing a dnn : machinelearning while a bit of an oversimplification , the answer here is that these parameters are often learned . these parameters aren't learned via backprop ( as the network parameters are ) but are chosen using cross validation . check out this blog post for an intro . URL EOQ usually people start with well known architecture like alexnet , vgg, inception and check how well it works for intended task . depending on the observation change are made-more layers , less layers , thickness, exotic layers , ensembles etc . EOA 
 iteration process of constructing a dnn : machinelearning while a bit of an oversimplification , the answer here is that these parameters are often learned . these parameters aren't learned via backprop ( as the network parameters are ) but are chosen using cross validation . check out this blog post for an intro . URL EOQ thanks ! EOA 
 iteration process of constructing a dnn : machinelearning while a bit of an oversimplification , the answer here is that these parameters are often learned . these parameters aren't learned via backprop ( as the network parameters are ) but are chosen using cross validation . check out this blog post for an intro . URL EOQ i , too, would like to hear some seasoned advice on how people go about choosing architecture details/parameters . EOA 
 iteration process of constructing a dnn : machinelearning while a bit of an oversimplification , the answer here is that these parameters are often learned . these parameters aren't learned via backprop ( as the network parameters are ) but are chosen using cross validation . check out this blog post for an intro . URL EOQ this may be helpful : URL EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ ok , thank you for your response ! EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ when have they not been ? some basic calculus might be taught in high school , but it's pretty standard to teach linear algebra after calculus i and ii , and those are usually first year subjects in most stem curricula . EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ they always have been . i took all three in high school but i was NUM ) very interested in math NUM ) privileged enough to have them taught by a cc prof on my high school campus . on the other side of the spectrum , i have friends who went to public high schools in chicago whom can barely do algebra . my anecdotal experience is that there aren't very many people doing calc ii / linear algebra in high school . EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ finishing university this year . also went to a public school . don't get me wrong , i think everyone should do all that math in high school , but my perception is that most people have no interest in pursuing it . at least at my high school students were allowed to stop taking math after algebra NUM , precalc, algebra NUM -one additional math class . most people not interested in math took ap or regular stats to fulfill the last class EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ very unlikely . machine learning requires you to have a good foundation in higher mathematics and computer science . wait until you have some statistical background and a stronger cs background to bother applying to something useful . your best bet is computer science internships like the other guy suggested . my cousin did an internship with microsoft at your age for computer science related things . EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ thanks ! do you have any recommendations as to where i could apply for internships ( i think the microsoft one is for local hs students ) ? EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ your best bet is to start in a role involving programming and data management . specifically targeting ml work in industry is most realistic at the graduate level ( master's or higher ) . EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ ok , thanks! what kind of companies should i be applying to ? i live in the bay area if that helps . EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ im not op but i am also interested in ml and am in high school . i am almost done with the coursera course with dr. ng and have a very strong math and algorithmic background but so far my only experience with ml has been the online course . EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ i'd recommend finding an open source project that interests you and start contributing there . even if you just write documentation , you'll learn a ton . if you have coding skills , then find bugs and fix them . you can start just by running code through static source code analysis to find things that need work . if you are actively contributing to that project , then when you have questions , the people on the project will be very receptive. you'll learn a ton more . i've never done an internship , but i've heard they can be mostly grunt work . picking an oss project might not get you paid , but you can work on absolutely any aspect of it that interests you . EOA 
 machine learning internships in hs ? : machinelearning probably not . to do anything meaningful other than apply out-of-the-box algorithms you need to know quite a bit university-level mathematics ( calculus i and ii and linear algebra at the very least ) . doing a cs internship is really common for people in college , but don't pigeon-hole yourself here ( e.g. by only doing one type of work ) . i don't know how early these are available , but would imagine that it's pretty uncommon for hs students to do internships ( though someone else should correct me on that ) . EOQ i'd recommend looking at academic institutions for this as they sometimes focus more on the person/drive than previous experience . i am a senior in university and had trouble finding places that would let me touch machine learning last summer . however, i'm interested in mls applications for biology so i started applying to labs to work on a bioinformatics project . EOA 
 how to learn machine learning from scratch ? : machinelearning full disclosure : i wrote this . i think it applies here . NUM steps to mastering machine learning with python you can likely skip the python basics . EOQ thanks alot ! that's exactly what i was looking for , i started andrew ng's course and i find it really good so far.Â´ how long does it take to learn all of this ? ( approx. ) EOA 
 how to learn machine learning from scratch ? : machinelearning full disclosure : i wrote this . i think it applies here . NUM steps to mastering machine learning with python you can likely skip the python basics . EOQ hard to say . depends on how much understanding you begin with . self study could likely get through the majority of this within a few months , spending sufficient time where needed . good luck ! EOA 
 how to learn machine learning from scratch ? : machinelearning full disclosure : i wrote this . i think it applies here . NUM steps to mastering machine learning with python you can likely skip the python basics . EOQ thanks a lot my friend . EOA 
 how to learn machine learning from scratch ? : machinelearning full disclosure : i wrote this . i think it applies here . NUM steps to mastering machine learning with python you can likely skip the python basics . EOQ start with andrew ng's machine learning lectures , then learn the scikit-learn library . it's already quite complete by itself , but even if you end up using something else for work , it's probably worth starting with scikit-learn since it's easy to use and very well documented . in particular you may want to get familiar with the scikit-learn cheat sheet . if you want to play with advanced neural networks ( not the vanilla multi-layer perceptron included in scikit-learn ) , you will probably need something more low-level such as theano or tensorflow , but you may want to already have a strong understanding of machine learning before you touch them . EOA 
 how to learn machine learning from scratch ? : machinelearning full disclosure : i wrote this . i think it applies here . NUM steps to mastering machine learning with python you can likely skip the python basics . EOQ thank you ! EOA 
 how to learn machine learning from scratch ? : machinelearning full disclosure : i wrote this . i think it applies here . NUM steps to mastering machine learning with python you can likely skip the python basics . EOQ URL EOA 
 how to learn machine learning from scratch ? : machinelearning full disclosure : i wrote this . i think it applies here . NUM steps to mastering machine learning with python you can likely skip the python basics . EOQ thank you ! EOA 
 basic question about dimensionality reduction : machinelearning my thoughts are as such : fit the pca on train set . transform test set . fit the random forest using pca.train.set then apply random forest to pca.test.set you want to keep your test set as independent of your training set as possible . if you do a pca on the train-test set then the values in your training set will be affected by your values in the test set . seems like contamination . EOQ it depends on what you're trying to do . training pca on just the training data is the most accurate model of a real application and generally the way to go . if it's kaggle , training pca on the full data set is fine ( though may not get you much beyond only the training data ) . for many industry applications you may have NUM times more unlabeled data as labeled data and it may help to train pca on that larger set plus the training data . and like shaker82 says , pca isn't necessary for random forests unless they're taking too long to train and/or can't fit in memory . EOA 
 basic question about dimensionality reduction : machinelearning my thoughts are as such : fit the pca on train set . transform test set . fit the random forest using pca.train.set then apply random forest to pca.test.set you want to keep your test set as independent of your training set as possible . if you do a pca on the train-test set then the values in your training set will be affected by your values in the test set . seems like contamination . EOQ but why would you apply any dimensionality reduction or pca before feeding rf ? keep in mind that rf can deal with high-dimensional data easily , as they select a random set of attributes for each induced tree , weak learner , so they do harvest the advantage of high variability . anyways, i am very interested in knowing how the performance changes ! EOA 
 best model for data with numbers and strings ? : machinelearning you definitely don't need any kind of nn for this . try something simple like naive bayes with outputs given country and any other attributes about the customer you may have . i would also suggest placing the number of books into classes/ bins ( ex NUM-10 , NUM-30 books of even larger bins depending on the magnitude of the purchases ) . if you get good results from nb then maybe go on to a random forest but be careful not to overfit ! EOQ take a look into factorization machines . fastfm seems a good starting point EOA 
 best model for data with numbers and strings ? : machinelearning you definitely don't need any kind of nn for this . try something simple like naive bayes with outputs given country and any other attributes about the customer you may have . i would also suggest placing the number of books into classes/ bins ( ex NUM-10 , NUM-30 books of even larger bins depending on the magnitude of the purchases ) . if you get good results from nb then maybe go on to a random forest but be careful not to overfit ! EOQ decision trees / random forests . EOA 
 does anyone do marketing and data science ? help please ? : machinelearning i do projects in this space for e-commerce companies , mostly in r , but if you're more familiar with python that's also ok . there are NUM things you can do relatively quickly with almost all web business : analyse their transactional data-to identify the seasonality in sales , generate forecasts ( using time series modelling ) analyse web traffic with google analytics ( using r package to access the data directly )-to find missed opportunities and low hanging fruits for improvement ( e.g. product pages with high conversion rate and low traffic ) customer analytics-calculate ltv ( using transactional data , data from crm and , for example , connecting it to data exported from ads systems like google adwords to take into account the costs of customer acquisition ) and generate insights for marketing team using some simple segmentation models ( rfm may be good enough in most cases ) that cases don't require a lot of statistics and machine learning skills ( linear and logistic regression will do ) , but to really wow your team with insights you should learn more about market basket analysis , decision trees , churn prediction , recommender systems , optimization and uplift modelling . for the basics on marketing analytics , i'd recommend this specialisation on coursera URL and following this twitter list i try to update once in a while URL EOQ hey man . you are awesome . could we talk for like NUM mins for max please ? i am really curious how you would use r to get deep analysis on google analytics . it seems like ga has data every where but using r can aggregate data together and find deeper insights . right? EOA 
 does anyone do marketing and data science ? help please ? : machinelearning i do projects in this space for e-commerce companies , mostly in r , but if you're more familiar with python that's also ok . there are NUM things you can do relatively quickly with almost all web business : analyse their transactional data-to identify the seasonality in sales , generate forecasts ( using time series modelling ) analyse web traffic with google analytics ( using r package to access the data directly )-to find missed opportunities and low hanging fruits for improvement ( e.g. product pages with high conversion rate and low traffic ) customer analytics-calculate ltv ( using transactional data , data from crm and , for example , connecting it to data exported from ads systems like google adwords to take into account the costs of customer acquisition ) and generate insights for marketing team using some simple segmentation models ( rfm may be good enough in most cases ) that cases don't require a lot of statistics and machine learning skills ( linear and logistic regression will do ) , but to really wow your team with insights you should learn more about market basket analysis , decision trees , churn prediction , recommender systems , optimization and uplift modelling . for the basics on marketing analytics , i'd recommend this specialisation on coursera URL and following this twitter list i try to update once in a while URL EOQ we do ml/data stuff for marketing and advertising too . i'm really excited about the opportunities to apply ml and data science to marketing-particularly given the industry trend towards quality over quantity . i'd recommend spending some time looking at the execution/actionable side of the data and how to apply your results . there are tons of cool things to learn in this area but in many cases you can be a bit handcuffed in how you use it depending on what channels and media buying platforms you use . two common tasks worth thinking about are audience analysis ( including segmentation , look-alike modeling , and affinity measurements ) and ad targeting . the first is great for understanding existing and potential customers , but your ability to apply these learnings can depend on your channel . if you spend some time looking at the facebook , twitter, or google ad platforms , you'll see that there are very different ( and limited ) ways you can translate your results into their targeting platforms . for things like email marketing-where you have more direct ability to identify audience ( versus interests or behaviors in the fb/google parlance )-this can be super useful . learning and predicting things about existing and potential customers is great , but knowing how , where, and when to apply what you learn can really help you understand what may be the most effective overall . EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ is there anyway everyone can contribute like that of ? they use blog sort of structure i am not entirely sure of the logistics but polymath project has generated some good results over the years i think it would be interesting if someone can setup polymath for machine learning . EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ here i just started a subreddit for the time being . this way we can see how many people would be interested . /r/polyml.project/new/ EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ cool ! can we keep track of notes ? how shall we log the progress ? any ideas . EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ the quality and number of unique responders on this thread is amazing . i think we can get a lot out of very-rapid online collaboration . i've written down my thoughts on what we can learn from polymath , and some other ideas : it would be a shame for us to split into pairs or triples . for each solved polymath problem there were NUM 's of contributors-since people aren't doing this full time , we're far more likely to finish projects as a really large group . it should obvious when a project is finished . luckily, we have many metrics to measure the performance of our models . for example , i might pose 'classify mnist by deep reinforcement learning' . proposals should be regulated in a decentralized way so we don't split our efforts too much-in fact until now polymath has only ever had NUM project at a time . potential consequences of this are our research scope being too narrow . i think NUM projects would be a nice compromise-it could instil some competitiveness in us . the proposals should have some element of novelty-people want to contribute to new things , not stuff that already exists . however, i do think some important projects could be replication of deepmind/facebook ai models whose source code isn't available . we could do this very quickly as a group . it should be as easy to contribute as making a comment on a thread . can anyone comment on what points they agree/disagree with ? i am thinking of hacking a quick website together . EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ you were right ! i was also amazed by the discussion . yeah polymath focusses on a single big problem at a time maybe it wont be right for ml as it has many branches and each problem is different in its approach . yeah proposals must be decentralized the thing is the project lead must have experience with publishing or handling large ml project so that that person can guide others in the right track . i am fine with more than NUM projects and nowadays ml is just too big . yeah projects can be of two types in my opinion where we implement unavailable models other aspect where embark on a completely big problem just to give an idea what happens when we stack billion layers to make very extreme deep net obviously there are lot of problems with such a problem which individually can be tackled in its own way . i think the best way is project being branched out and even if people work individually they can reconcile with others work and adapt their methods . also in my personal opinion subreddit for polyml doesn't work , maybe i am wrong but previously it happened that people forget the existence of subreddits so i think it would be great if someone sets up blog like thing such as here where it would be more organized and if an eminent personality is posting it will drive traffic ,make it more interesting and finally results will be out which is exactly the case in polymath where even field's medalists contribute . let me know your opinions ! EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ-100 for this idea !!! EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ thanks ! EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ what kind of problems are you wanting to work on ? EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ hi , i've done an msc in ai/robotics and i'm currently a phd student in the field-my current research revolves around exploring and modelling robotic value systems and motivations for decision making using neural networks . at the moment , NUM hours a week is a bit of a stretch , but i'd be happy to explore some ideas . drop me a message ! EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ i'm in the same boat . should we turn this thread into a match-making service ? EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ i'm working on some nlp and computer vision projects . i don't have any degree in ai but i'm highly interested in this field . i would love to share my project and ideas/problems with you that i try to solve and perhaps work together if you are interested in one of these projects :-) EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ i`m currently master student with nlp and ml specialization . i am interested in doing some experiments on nlp with nn . EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ masters here as well in pretty much the same things . i spent about NUM months working with nlp and nns . what nlp activities are your interested in performing ? nns wouldnt be my first choice when approaching nlp problems after my experiences , but ( i believe ) it might be due to the frame work i was working in/ EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ hi , my interest is mainly in cross-lingual projection/learning . i.e. projecting coreference/referring expressions from resource rich languages to resource poor languages . EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ currently doing my msc in machine learning . wanted to do the same kind of work , we can talk on mail ! EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ this is pretty awesome . i'm also trying to focus on machine learning research . EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ i'd love to be a research buddy , i studied ai and machine learning as an undergrad and am currently pushing the limits of what i can do on a run of the mill laptop , what type of data sets are you working with ? EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ and what city are you in ? have you thought about looking at meetup.com ? EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ heyo , looks like you've got plenty of responses already , but i'm interested . i've been stalled out a bit , i was doing work with combining neural networks and evolutionary algorithms but didn't have a problem to solve . i'd love to chat and do research and play around with new ways of using neural nets and ai . NUM hours a week would be very easy , if we started doing interesting stuff i could ramp that up to even more . EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ what kind of hardware are we talking ? anything published ? EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ phd student located in england and studying the influence of news-sentiment on stocks ( ai/ml group ) open to share my current challenges . drop me a message ! EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ i'm interested : just a simple programmer , but trying to do some ml on the sideline because of interest . EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ wow . i am impressed . i didn't expect so many responses . i literally had to go through at least NUM messages . i had to filter out some people , because i can't communicate with so many . i like the polymath idea , though it would probably miss some of the things i find important that i would like to do-have skype discussions over internet . that is not easily done in a project like this . btw , while i was in the middle of writing the message my friend in the corridor stole my door , so i had to get it back :-d EOA 
 looking for a research buddy : machinelearning alternative is to start a blog and share your experience there EOQ i m a graduate with one year experience as a data scientist , i m interested in talking more about the work you are thinking about . EOA 
 'no module named tensorflow' error when trying to run tensorflow : machinelearning the pip command you have in your path probably does not match the python command you have in your path . try pip show tensorflow to see where it is installed . to install a package to the matching version of python , either use the absolute path or do : python-m pip install /path/to/tensorflow-version-platform.whl also if you have different version of python installed on your system , i would recommend to avoid messing with pythonpath but instead learn to use virtualenv ( and optionally virtualenvwrapper on top ) to properly isolate once from the others . alternatively you can use conda and conda envs but do not mix the NUM kinds of environments . EOQ okay . since i already installed it using the pip command , should i uninstall that first and then install it using virtualenv ? or should i install the package with pip to the matching version of python ? what would you recommend ? or would it be best , since i already messed around , to uninstall python completely and reinstall using virtualenv ? EOA 
 'no module named tensorflow' error when trying to run tensorflow : machinelearning the pip command you have in your path probably does not match the python command you have in your path . try pip show tensorflow to see where it is installed . to install a package to the matching version of python , either use the absolute path or do : python-m pip install /path/to/tensorflow-version-platform.whl also if you have different version of python installed on your system , i would recommend to avoid messing with pythonpath but instead learn to use virtualenv ( and optionally virtualenvwrapper on top ) to properly isolate once from the others . alternatively you can use conda and conda envs but do not mix the NUM kinds of environments . EOQ when you create a virtualenv , you isolate yourself from packages that are installed on the system python , so it does not matter to uninstall tensorflow at the toplevel . to install packages inside a virtualenv you also use pip , but the pip command from within the bin folder of that virtualenv . read the virtualenv documentation for details . anyway , before trying things at random try to understand what the problem is . have you checked where tensorflow was installed by your pip command with pip show tensorflow ? do you have several versions of python concurrently installed on your system ? which one is the one pointed to by the python command in your path ? you can try just to display the version : python-version to see the location where packages should be installed for this python command you can do : python-c from distutils.sysconfig import get.python.lib ; print(get.python.lib()) i suspect that your pip and python commands in your path are not aligned . you should use the pip version that matches you python command . EOA 
 'no module named tensorflow' error when trying to run tensorflow : machinelearning the pip command you have in your path probably does not match the python command you have in your path . try pip show tensorflow to see where it is installed . to install a package to the matching version of python , either use the absolute path or do : python-m pip install /path/to/tensorflow-version-platform.whl also if you have different version of python installed on your system , i would recommend to avoid messing with pythonpath but instead learn to use virtualenv ( and optionally virtualenvwrapper on top ) to properly isolate once from the others . alternatively you can use conda and conda envs but do not mix the NUM kinds of environments . EOQ you could easily try everything you just said in under NUM minutes EOA 
 k-means when some data is missing ? : machinelearning so you want to make k-means work with nans ? write yourself a custom distance function . depending on the nature of your nans , either ignore them ( if they're random ) or penalize them ( if two similar records are likely to have nans in the same columns ) . EOQ i would recommend /u/rasbt 's option ( c1 ) , but with the addition of a new binary feature representing whether the original feature was missing or not . in this sense , you're able to see if missingness is indicative of a new cluster . EOA 
 k-means when some data is missing ? : machinelearning so you want to make k-means work with nans ? write yourself a custom distance function . depending on the nature of your nans , either ignore them ( if they're random ) or penalize them ( if two similar records are likely to have nans in the same columns ) . EOQ there are many different approaches for dealing with missing values , some of them are a) if you have a lot of samples and relatively few have missing values in certain feature columns , one approach would be to remove these samples entirely b) if you have a relatively large number of feature columns and you can afford deleting some of those with missing values , delete the entire feature columns instead of the individual samples c) a maybe better way to deal with missing values could be some sort of imputation . the simplest imputation techniques may be : c NUM ) replace the missing values in a feature column by the feature column's mean value ( or mode ) c NUM ) replace the missing values in a feature column by the feature value mean ( or mode ) of its k nearest neighbors ( based on other features ) EOA 
 k-means when some data is missing ? : machinelearning so you want to make k-means work with nans ? write yourself a custom distance function . depending on the nature of your nans , either ignore them ( if they're random ) or penalize them ( if two similar records are likely to have nans in the same columns ) . EOQ there is a whole lot of ways to go about this , not all of them good . the most simple way , if you have a lot of data and not a lot of missing values , is just deleting the datapoints where a value is missing . however, if this leads to deleting half your data , you might want to try some data imputation . EOA 
 k-means when some data is missing ? : machinelearning so you want to make k-means work with nans ? write yourself a custom distance function . depending on the nature of your nans , either ignore them ( if they're random ) or penalize them ( if two similar records are likely to have nans in the same columns ) . EOQ in r you can try 'mice' package ( if you need to keep rows with nas ) (URL) EOA 
 k-means when some data is missing ? : machinelearning so you want to make k-means work with nans ? write yourself a custom distance function . depending on the nature of your nans , either ignore them ( if they're random ) or penalize them ( if two similar records are likely to have nans in the same columns ) . EOQ k-means is actually a special case of the more general em-algorithm for gaussian mixtures . k-means makes two assumptions : NUM ) each cluster is a multivariate gaussian with unit variances ; NUM ) on the e-step it maximizes over a subset of all distributions-over delta function ( that is deterministic assignments to clusters ) . the general form of the em-algorithm readily handles missing values . EOA 
 k-means when some data is missing ? : machinelearning so you want to make k-means work with nans ? write yourself a custom distance function . depending on the nature of your nans , either ignore them ( if they're random ) or penalize them ( if two similar records are likely to have nans in the same columns ) . EOQ not sure i got you .. what i'm trying to do , is given n parameters of m different examples , classify them to k different classes . for some of the samples , some of the parameters are missing . i can't seem to understand how em helps me here .. could you be more specific , please? EOA 
 k-means when some data is missing ? : machinelearning so you want to make k-means work with nans ? write yourself a custom distance function . depending on the nature of your nans , either ignore them ( if they're random ) or penalize them ( if two similar records are likely to have nans in the same columns ) . EOQ ok , let's firstly understand how is em related to k-means . to use em you have to define the observed variables ( m x n matrix x , features of the examples ) , the hidden variables ( m x NUM vectorz , for each object it's the index of the cluster this object belongs to ) , the parameters ( k x n matrix w , centers of the clusters ) , and the probabilistic model ( you sample iid objects from a mixture of gaussians ) . now to do maximum likelihood training you maximize p(x | w) w.r.t. w . this is a hard optimization problem and em-algorithm suggests to approximately solve it by iteratively repeating two steps : e-step , where you find the closest distribution q(z) to the posterior p(z | x , w-) using the current estimate of w-. usually, it's the posterior itself : q(z)-p(z | x , w-). m-step , where you maximize w.r.t. w the expectation over q of log p(x , z | w) , that is w-argmax e.q log p(x , z | w) . in k-means on the e-step you are looking for the closest distribution q to the posterior among delta-functions , so you find the best assignment z-of each object to the current set of the clusters w-. since you are using delta-functions , on the m-step the expectation over q becomes just one particular value : e.q log p(x , z | w)-log p(x , z-| w) . now , if you want to handle missing values you just define corresponding variables to be hidden ( instead of observed ) . so on the e-step , you will find a distribution on the variables z and on the missing variables from x . the distribution on the missing values will probably be a gaussian mixture , and you will have to take the expectation on the m-step ( which is simple with gaussians ) . if this approach is something you would like to try , i can derive the final formulae for this k-means-em-algorithm with support of the missing values . but this comment is already way too big , so maybe it's the right time to start a blog :) EOA 
 k-means when some data is missing ? : machinelearning so you want to make k-means work with nans ? write yourself a custom distance function . depending on the nature of your nans , either ignore them ( if they're random ) or penalize them ( if two similar records are likely to have nans in the same columns ) . EOQ hi , yes i would very appreciate if you could .. my understanding of em is pretty much what can be found here . any further knowledge will be appreciated .. EOA 
 k-means when some data is missing ? : machinelearning so you want to make k-means work with nans ? write yourself a custom distance function . depending on the nature of your nans , either ignore them ( if they're random ) or penalize them ( if two similar records are likely to have nans in the same columns ) . EOQ first of all you should know what information is represented by the missing values and why it may be missing , see URL . how to proceed depends on the cause of the nas . EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ i am not familiar with sonic . what results were you expecting for those words ? EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ nothing sonic related , but something like friend or partner . EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ hmm ... i do see friend for at least a few results ( granted they are in the middle of the list ) for companion . maybe i should think of a way to rank the find results by the actual euclidean distance whenever possible . sadly , it looks like competitions doesn't come up when you type in competitive . maybe i should look into using word lemmas or word stemming to look for common roots between words . i kinda have been avoiding doing this because i never personally find that useful . EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ great idea and work ! i looked a bit into your code and i wonder what motivates the choices of : NUM ) keep only the NUM closest words from glove ( knn-NUM ) NUM ) after this , keeping only the words with a squared distance less than NUM keep up the good work ! EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ excellent questions ! those choices are rather arbitrarily except the fact that i do want to control both of those parameters at some point . at first i started by using word2vec's vectors and i had a much better sense of what would be a good and acceptable radius for vectors . since i switched to glove and stopped taking the square root of the euclidean distance , i lost the sense of just what those parameters should be . but you're right , i am going to fine tune them in the near future . right now the radius2 of NUM is a bit too much since i often see unrelated words in the results . EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ fantastic idea-i could see this being applied everywhere ! smart to use the pre trained glove and word2vec ! EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ very nice little project . with all the new embedding tech that's arriving , i could see this evolving into quite a sophisticated and useful search tool . EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ this is an awesome idea . it's one of those things where the moment i read the post title i thought holy crap that's brilliant without even reading the rest of the post . EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ that's a really cool idea ! what motivated the decision to use euclidian distance over the more standard cosine measure ? EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ that's a really good question . i guess we can be a little bit more robust to the actual word vector model if we use a proper distance function . in other words , using the cosine measure , you might assume that the length of all vectors is the same so it's good enough to just use the direction . this may or may not be true with glove ( i didn't check that the lengths are all the same ) . do you think i should switch to cosine similarity ? EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ i don't have too much direct experience using euclidian vs cosine myself , but levy & goldberg looked at that in one of their awesome word embedding papers . URL in preliminary experiments , we tried the four different normalization schemes described above ( none , row, column , and both ) , and found the standard l2 normalization of wâs rows ( i.e. using the cosine similarity measure ) to be consistently superior if you're not familiar with levy and goldberg , they're awesome ! they have been producing a few really cool papers that analyze the mathematics and models behind what makes word2vec work-factoring an sppmi matrix , NUM cos-multiply, dependency-based word embeddings . this most recent tacl NUM paper is so good-it breaks down every little detail of what makes word2vec so good . tl;dr i can't comment definitively , but i'd learn towards cosine . EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ this is brilliant , making this my default ctrl-f search right now EOA 
 i made a ctrl-f like chrome extension which gives fuzzy matches using word vectors ( glove/word2vec ) : machinelearning this is a really cool idea ! tried it on the ( no shame ) and got less than stellar results for queries like companion and competitive . definitely looking forward to see how this evolves ! EOQ i'm honored . :d EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ ilya sutskever , john schulman , wojciech zaremba , andrej karpathy , durk kingma , greg brockman EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ finally we'll know what movie is musk's favourite EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ isn't it obvious ? terminator ! EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ i would have though iron man . EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ i don't think elon musk will come to this ama . the announcement said the research team . EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ /u/jokeexplainbot EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ the short version of my question is this-does openai have any plans to offer courses or other learning opportunities to people interested in the ml field who want to become well-versed in state-of-the-art methods and apply these in real-world situations for companies , governments, ngos and other organisations globally ? the much longer version of my question is this- as your website points out , and as will be familiar to everyone on this sub , progress in the machine learning field over the last NUM-5 years has been dramatic , and human-level performance has been achieved in tasks that many thought would prove extremely difficult . tools such as deep learning , lstm and others have provided broadly powerful techniques that , it is likely , can be applied to diverse problems and data-sets . i have read ( somewhere! ) that google now has hundreds of teams working to apply machine learning techniques to provide services within google's business . as we are all aware , google are not alone-and several major tech companies are moving rapidly to apply machine learning to their businesses . in order to acquire the talented people necessary for this effort , tech companies have basically strip-mined academia to acquire the best and brightest . in some respects , this is understandable , and no-one could criticise individuals for getting the best reward for their considerable skills . however, this means that academic programmes simply do not have the personnel or resources to expand and train a much larger corpus of people in this field . on-line courses exist , but arguably some of them are already out-of-date and do not reflect the important developments in the field . and simply taking an online course does not build the kind of credibility that companies need before allowing aspiring data scientists near their data . without a significant expansion in the teaching capacity of the ml field then it seems to me that what will happen is that large tech firms , banks and hedge funds will dominate and monopolise the market for people with skills in this field . instead of machine learning building value for everyone ( as you aspire to on your website ) the effect will be to entrench existing monopolies or oligopolies in the tech and finance spaces . the lack of teaching capacity as i have called it above will create a huge bottleneck and the value that could be created from applying these tools and methods to datasets and problems globally , in all kinds of sectors and countries-from governments to ngos to manufacturing companies , to insurance companies , etc. etc . will instead not be realised , and ( even worse! ) what value that is realised will concentrate in the hands of the already successful . geographically, the effect will be particularly extreme-us universities and corporations already dominate ml research and this situation is unlikely to change . if the everyone that openai intends to benefit includes the rest of the world then this is a real challenge . i realise that this isn't a research question , and that your response may be to say we are doing our best to create value for everyone by making our research open source . but, with the greatest of respect , this approach won't succeed . without people to apply the methods and techniques you develop , the benefits will not flow to companies and individuals globally . the state-of-the-art of the field may progress dramatically , even to human-level general intelligence , but the ability to apply these techniques will remain concentrated in very few companies . this will create dramatic winners and losers , rather than benefit for all . the key issue seems to me to be teaching capacity . how can we create the NUM s of machine learning experts ( per year ) the world could easily use and benefit from ? as a step towards this , openai could commit to hiring a group of top-level researchers in the field , who would be interested in creating a taught programme , with exams , with accreditation etc . to provide ml experts , familiar with the state-of-the-art in the field , but perhaps interested in applying it to real world problems and data-sets rather than advancing the field through novel research . i think openai , as a non-profit institution but one that's not constrained by the issues of academia , would be ideally placed to do this . and it would result in real progress in your objective to build value for everyone . thanks in advance for any thought you may have on this . EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ looking forward to it ! EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ you god damn great moderators , god damn great ! EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ awesome !! :) can't wait to hear what this amazing team has to say . EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ that is so great ! looking forward :) EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ expecting questions related to deep learning . EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ maybe i should ask : which is better-logistic regression or naive bayes ? EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ i know this is a joke , but in case you were actually interested : URL EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ holy crap , i cannot believe how specific this paper is to my question . thanks! now that ng and jordan have answered that question , i'll just have to ask : what's better classification or regression ? i dare someone to answer that one :p EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ that's brilliant ! i'm looking forward to it ! EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ [ deleted ] EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ are you sure you wanted a reminder for saturday the NUM th and not saturday the NUM th , when the ama is going on ? EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ see , that's why need openai ;) EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ messaging you on NUM-01-16 NUM :00:00 utc to remind you of this . click this link to send a pm to also be reminded and to reduce spam . parent commenter can delete this message to hide from others . [ faqs ] [custom] [ your reminders ] [feedback] [ code ] EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ do you guys think there might already be huge breakthroughs in ai that's kept secret in military research labs somewhere ? how would you guys react if this was revealed at a given time but the technologies were kept secret ? how can you help open this kind of malicious ai ? thanks ! EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ you guys should definitely expect questions about hiring process !! :) looking forward to it . EOA 
 the openai research team will be doing an ama in /r/machinelearning on january NUM : machinelearning could the admin also mention the specific names of the team ? or we should assume all of the research members listed in the website will come to this ama ? EOQ very nice , looking for to that and asking them about ai for good as discussed here : URL EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ you can , although i find hard to imagine a reason to use vba over other languages for this purpose . EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ only have vba on my work computer EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ if you have the chance you should probably think about installing python . EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ im new to the corporate world . can i just install whatever i want on my computer ? EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ damn you are just like me . i am not allowed to install python nor r at work . terrible life . EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ really ? what do you do and why cant you ? EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ work at a huge brewing company in which the corporate people fear data leakage . seriously they are very it illiterate . EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ hahahahaha EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ me so funny ? EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ i personally spend as much time as possible on excel , but considering serious ml requires a gpu , vba is not even close to what you'll need . EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ wouldn't recommend it , but technically you can . EOA 
 can you code machine learning in vba ? : machinelearning vba is turing complete , so i don't see why not . is there a particular reason you want to code ml in vba ? i'd imagine it would be pretty slow for any reasonably sized data set ? edit : let me google that for you EOQ download a book called data smart . the author applies some data science algorithms entirely in excel . EOA 
 stacked denoising autoencoders : cannot reproduce the filters : machinelearning thanks for the swift reply . agreed , this could be due to the smaller sample size . thanks for mentioning . as i did it , the ae is probably just overfitting on the noise pattern . so i put in a gaussiannoiselayer after the input . unfortunately, the filters dont look much different ( they contain more structure , but still nowhere near those edge detectors in the paper ) . a more fundamental question : what encoder/decoders to use ? from the paper i figured that they use some nonlinearity in the encoder ( probably sigmoid ) and the decoder is affine. also they talk about tying the weights of the encoder/decoder . i would understand this if encoder and decoder are the same class ( e.g. both sigmoids ) . why is it reasonable to tie the weights of a nonlinear activation function and a linear one ? doesn't this force the nonlinearity to state in the linear regime ? EOQ sigmoid encoder-linear decoder ( squared error loss ) or sigmoid encoder-sigmoid decoder ( cross-entropy loss ) are the two setups they use in the paper , they talk about this in section NUM . they talk about the use of tied weights on page NUM , but you should play with untied weights to check it out . if you can increase the sample size it should help , having an order of magnitude more information is useful for unsupervised stuff like this . also , another good source of info is the theano tutorials , here's the one for denoising autoencoders EOA 
 stacked denoising autoencoders : cannot reproduce the filters : machinelearning thanks for the swift reply . agreed , this could be due to the smaller sample size . thanks for mentioning . as i did it , the ae is probably just overfitting on the noise pattern . so i put in a gaussiannoiselayer after the input . unfortunately, the filters dont look much different ( they contain more structure , but still nowhere near those edge detectors in the paper ) . a more fundamental question : what encoder/decoders to use ? from the paper i figured that they use some nonlinearity in the encoder ( probably sigmoid ) and the decoder is affine. also they talk about tying the weights of the encoder/decoder . i would understand this if encoder and decoder are the same class ( e.g. both sigmoids ) . why is it reasonable to tie the weights of a nonlinear activation function and a linear one ? doesn't this force the nonlinearity to state in the linear regime ? EOQ ok , i figured it out ! it is in fact the sample size : if i go up to NUM ( instead of NUM ) samples , i do get the kind of filters they report in the paper . i just didn't expect that the sample size changes the results/filters so drastically and sacrificed it for faster training . however, in hindsight it makes kind of of sense that NUM samples are probably not enough for a network with ~30000 parameters . thx for helping me out here ! EOA 
 stacked denoising autoencoders : cannot reproduce the filters : machinelearning thanks for the swift reply . agreed , this could be due to the smaller sample size . thanks for mentioning . as i did it , the ae is probably just overfitting on the noise pattern . so i put in a gaussiannoiselayer after the input . unfortunately, the filters dont look much different ( they contain more structure , but still nowhere near those edge detectors in the paper ) . a more fundamental question : what encoder/decoders to use ? from the paper i figured that they use some nonlinearity in the encoder ( probably sigmoid ) and the decoder is affine. also they talk about tying the weights of the encoder/decoder . i would understand this if encoder and decoder are the same class ( e.g. both sigmoids ) . why is it reasonable to tie the weights of a nonlinear activation function and a linear one ? doesn't this force the nonlinearity to state in the linear regime ? EOQ that really doesn't surprise me , more data is almost always a great thing , glad you could get it working ! EOA 
 two new deep reinforcement learning papers from google deepmind at jan NUM ! : machinelearning these were posted on december NUM and NUM . EOQ i didn't know that sorry :/ they are good papers anyway :p EOA 
 two new deep reinforcement learning papers from google deepmind at jan NUM ! : machinelearning these were posted on december NUM and NUM . EOQ i think the second paper is actually older than december , i remember reading that in october . but interesting find on the first paper ! EOA 
 looking for musical dataset with same note played by different instruments ! : machinelearning i just did my dissertation on recognizing musical notes ! you can find free data from the or the . the latter site features scales that you will have to split apart for individual notes . for this task , use /r/audioengineering , /r/musictheory or /r/wearethemusicmakers : URL that one has links like URL and also a lot of orchestrators seem to be using the symphobia , vienna or east/west sample libraries e.g. URL ( would be interested to see your results . after you tease out adsr envelope and harmonic structure as inputs , are there many inputs left over? ) EOA 
 looking for musical dataset with same note played by different instruments ! : machinelearning i just did my dissertation on recognizing musical notes ! you can find free data from the or the . the latter site features scales that you will have to split apart for individual notes . for this task , use EOA 
 looking for musical dataset with same note played by different instruments ! : machinelearning i just did my dissertation on recognizing musical notes ! you can find free data from the or the . the latter site features scales that you will have to split apart for individual notes . for this task , use EOA 
 looking for musical dataset with same note played by different instruments ! : machinelearning i just did my dissertation on recognizing musical notes ! you can find free data from the or the . the latter site features scales that you will have to split apart for individual notes . for this task , use EOA 
 looking for musical dataset with same note played by different instruments ! : machinelearning i just did my dissertation on recognizing musical notes ! you can find free data from the or the . the latter site features scales that you will have to split apart for individual notes . for this task , use EOA 
 looking for musical dataset with same note played by different instruments ! : machinelearning i just did my dissertation on recognizing musical notes ! you can find free data from the or the . the latter site features scales that you will have to split apart for individual notes . for this task , use EOA 
 looking for musical dataset with same note played by different instruments ! : machinelearning i just did my dissertation on recognizing musical notes ! you can find free data from the or the . the latter site features scales that you will have to split apart for individual notes . for this task , use EOA 
 looking for musical dataset with same note played by different instruments ! : machinelearning i just did my dissertation on recognizing musical notes ! you can find free data from the or the . the latter site features scales that you will have to split apart for individual notes . for this task , use EOA 
 deep belief network with tensorflow : machinelearning dbns are quite outdated , which probably explains why nobody has bothered to code them up in tensorflow yet . is there any reason why you're interested in this type of model in particular ? EOQ i want to solve a problem such as titanic dataset machine learning for kaggle . ( URL ) as far as i know , cnn and rnn is not proper for such quests and dbns is better than pure dnn . is my knowledge wrong ? EOA 
 deep belief network with tensorflow : machinelearning dbns are quite outdated , which probably explains why nobody has bothered to code them up in tensorflow yet . is there any reason why you're interested in this type of model in particular ? EOQ why dou you think dbns are better than regular dnns ? they are different types of models . you can pre-train a dnn using a dbn , but this is an outdated technique . pre-training is rarely useful these days ( except when you have very little labeled data and lots of unlabeled data ) . if you really need to pre-train you can use something like an autoencoder , which is a much simpler model with a tractable gradient . EOA 
 deep belief network with tensorflow : machinelearning dbns are quite outdated , which probably explains why nobody has bothered to code them up in tensorflow yet . is there any reason why you're interested in this type of model in particular ? EOQ thanks for your advise ! EOA 
 deep belief network with tensorflow : machinelearning dbns are quite outdated , which probably explains why nobody has bothered to code them up in tensorflow yet . is there any reason why you're interested in this type of model in particular ? EOQ someone correct me if i'm wrong but , denoising autoencoders ( dae ) are actually equivalent to gaussian rbms trained on score matching . i woudn't say that pre-training in general , or dbns , are outdated ; they are just different models , they are generative , while autoencoders typically aren't ( they can be thought ) . now , if you want a generative model , you can use either dbns or generative stochastic networks ( gsn )-the latter use auto-encoders to learn the probability density function of the data . why you should use one over the other , it's not that clear : for some problems dbns are better , for others autoencoders seem to do the job . i don't want to go off in a tangent but if anyone has a some details on why one should use one model over the other , i would appreciate it . as for the implementation , i was planning on coming up with one . if this still interests you i will let you know /u/ycyoon EOA 
 deep belief network with tensorflow : machinelearning dbns are quite outdated , which probably explains why nobody has bothered to code them up in tensorflow yet . is there any reason why you're interested in this type of model in particular ? EOQ yes , not for this task for sure , you're right . what i meant to say was that you could consider it if you really need the generative properties of the model , and even then , it depends on the domain . at the end of the day the lesson here is : if you have a hammer , don't start hammering down on all the screws you find . EOA 
 machine learning and mp4 video files : machinelearning this depends . based on what ? relevant xkcd . categorizing the videos by machine learning is possible , but whether or not it's feasible in the short term depends on what you want to categorize based on EOQ amusingly , we have the tools and data sets to check whether a given photo is of a bird pretty easily nowadays . what are these mp4 video files and what information are you hoping to extract from them ? EOA 
 most important cnn papers from the past few years ? : machinelearning batch normalization is arguably the most important new technique for cnn training since NUM imo . a lot of the rest are subfield specific , e.g. techniques batch normalization better sgd methods ( rmsprop , adam, ... ) stns network architectures googlenet vgg-16/19 msra resnet ( very new ) object detection {fast,faster,}-rcnn unsupervised learning gan ladder networks EOQ it's a fast moving field so lists become outdated quickly , but i tried to organize cnn and rnn papers by topic ( in an easy-to-difficult progression ) for my deep learning seminar class : URL hope this helps ! EOA 
 most important cnn papers from the past few years ? : machinelearning batch normalization is arguably the most important new technique for cnn training since NUM imo . a lot of the rest are subfield specific , e.g. techniques batch normalization better sgd methods ( rmsprop , adam, ... ) stns network architectures googlenet vgg-16/19 msra resnet ( very new ) object detection {fast,faster,}-rcnn unsupervised learning gan ladder networks EOQ awesome deep vision : URL EOA 
 request: python implementation of machine march madness : machinelearning start by looking through the kaggle competitions : URL there's not much in the way of python code on my blog , but you can look at : URL which is a series of NUM python notebooks about implementing the massey rating . pm me for more info/discussion . EOQ URL EOA 
 anyone know of a good tutorial for coding rnns ? : machinelearning generally speaking , you should avoid looking at neuroscience papers as little more than inspiration for what you're implementing . try looking at something like the deeplearning tutorials ( here : URL ) much neuroscience is no longer directly applicable to machine learning . it is best not to think of modern deep learning systems as analogs to neural systems in the real world and think of them as end-to-end differentiable systems that can model complex nonlinear systems . EOQ thanks the tutorial link , i will go through it ! it seems like there are quite a few good theano examples / tutorials , so i'm definitely trying that out , in parallel with my torch implementation . regarding the comment about neuroscience , full disclaimer , i'm a phd student in neuroscience , interested in neural networks bc simple implementations of them in some contexts do quite a good job of estimating how cortex might solve a certain problem . so i'm interested in replicating some of the early neuroscience related neural networks because of that-not necessarily because i want to solve a practical task . ;) EOA 
 anyone know of a good tutorial for coding rnns ? : machinelearning generally speaking , you should avoid looking at neuroscience papers as little more than inspiration for what you're implementing . try looking at something like the deeplearning tutorials ( here : URL ) much neuroscience is no longer directly applicable to machine learning . it is best not to think of modern deep learning systems as analogs to neural systems in the real world and think of them as end-to-end differentiable systems that can model complex nonlinear systems . EOQ here is some interesting lecture material on approximating brain functions with neural networks . sometimes a bit dense but very interesting . URL e : very little on deep networks . EOA 
 anyone know of a good tutorial for coding rnns ? : machinelearning generally speaking , you should avoid looking at neuroscience papers as little more than inspiration for what you're implementing . try looking at something like the deeplearning tutorials ( here : URL ) much neuroscience is no longer directly applicable to machine learning . it is best not to think of modern deep learning systems as analogs to neural systems in the real world and think of them as end-to-end differentiable systems that can model complex nonlinear systems . EOQ that looks really interesting , thanks! EOA 
 anyone know of a good tutorial for coding rnns ? : machinelearning generally speaking , you should avoid looking at neuroscience papers as little more than inspiration for what you're implementing . try looking at something like the deeplearning tutorials ( here : URL ) much neuroscience is no longer directly applicable to machine learning . it is best not to think of modern deep learning systems as analogs to neural systems in the real world and think of them as end-to-end differentiable systems that can model complex nonlinear systems . EOQ reasonable enough . i actually spoke to a neuroscientist in training ( phd student , i think a different area than you though ) recently , and i think it would be a good idea to simply try to raise your base knowledge before trying to implement any structures . this is simply because coming into any topic with no knowledge you're going to shoot yourself in the foot by making simple mistakes that could be easily avoidable through some direction . i would recommend following this course ( URL ) . it doesn't deal directly with rnns , but it will give you a good background from which you can start as well as a way of thinking about modelling these kinds of problems which would take you a good deal of time to learn on your own . best of luck:) EOA 
 anyone know of a good tutorial for coding rnns ? : machinelearning generally speaking , you should avoid looking at neuroscience papers as little more than inspiration for what you're implementing . try looking at something like the deeplearning tutorials ( here : URL ) much neuroscience is no longer directly applicable to machine learning . it is best not to think of modern deep learning systems as analogs to neural systems in the real world and think of them as end-to-end differentiable systems that can model complex nonlinear systems . EOQ haha , i'm taking that course next quarter ! thanks for the suggestion ;). assume i have some reasonable baseline familiarty with machine learning ( ie . i've taken andrew ngs cs NUM class , and percy liangs cs NUM ) , but that my familiarity with neural networks is mainly through online tutorials . lots for convolutional networks exist , but fewer exist for recurrent nets , i think ... just trying to get some practice ! EOA 
 anyone know of a good tutorial for coding rnns ? : machinelearning generally speaking , you should avoid looking at neuroscience papers as little more than inspiration for what you're implementing . try looking at something like the deeplearning tutorials ( here : URL ) much neuroscience is no longer directly applicable to machine learning . it is best not to think of modern deep learning systems as analogs to neural systems in the real world and think of them as end-to-end differentiable systems that can model complex nonlinear systems . EOQ we just published this about rnns in dl4j , if it's helpful : URL EOA 
 anyone know of a good tutorial for coding rnns ? : machinelearning generally speaking , you should avoid looking at neuroscience papers as little more than inspiration for what you're implementing . try looking at something like the deeplearning tutorials ( here : URL ) much neuroscience is no longer directly applicable to machine learning . it is best not to think of modern deep learning systems as analogs to neural systems in the real world and think of them as end-to-end differentiable systems that can model complex nonlinear systems . EOQ thanks for the link ! more tutorials more better ! incase anyone else finds this thread looking for tutorials , i found this : URL one to be really helpful . i've got the basic set-up i was looking for working in both theano and torch ... now on to fine tuning . EOA 
 gpu based training of crfs : machinelearning gpus are much more useful for batch operations ( e.g. convolutions ) than sequential operations thus it is hard to parallelize a crf on a gpu . take a linear chain crf as an example . the label at each timestep t is dependent on the label at t-1 . thus, for exact inference , you must perform your computations sequentially . chain crfs are similar to rnns so you might want to look at rnn implementations for reference . inference in an rnn is also sequential-hence why they tend to take longer to train than feedforward networks . you might be able to perform approximate inference efficiently on a gpu ? alternatively, you could also use a gpu to simply compute the unaries for your crf . edit : one last reference . if you're doing something like semantic segmentation you might want to look at the 'crf as rnn' paper from iccv16 : URL EOQ i've never heard of a library to do this , but like /u/colinscl said , if you're pretty clever , i think you might be able to get there , but i bet you're going to end up writing your own libraries . EOA 
 how do you determine whether you're overfitting when using random forest and other tree models ? : machinelearning tune your hyperparameters using your cross-val set ( NUM % ) , then use your test set ( NUM % ) to guess your error rate in the wild . EOQ just edited in a clarification , i'm wondering about other sources of overfitting as well such as having too many features EOA 
 how do you determine whether you're overfitting when using random forest and other tree models ? : machinelearning tune your hyperparameters using your cross-val set ( NUM % ) , then use your test set ( NUM % ) to guess your error rate in the wild . EOQ l1 and l2 regularization can be viewed as just more hyperparameters . EOA 
 how do you determine whether you're overfitting when using random forest and other tree models ? : machinelearning tune your hyperparameters using your cross-val set ( NUM % ) , then use your test set ( NUM % ) to guess your error rate in the wild . EOQ i think in a sense you are both right . just the mere fact of having your training set accuracy be significantly lower than your validation set could likely imply the potential to trade training accuracy for a boost in generalization ( validation accuracy. ) so on the one hand , i do think overfitting only really occurs if there is a possible trade to occur there . but, usually there is by tuning parameters like maximum depth , regularization, etc . so in my experience , having a significantly lower training accuracy almost always means overfitting is happening , even if it's not the definition of overfitting . EOA 
 how do you determine whether you're overfitting when using random forest and other tree models ? : machinelearning tune your hyperparameters using your cross-val set ( NUM % ) , then use your test set ( NUM % ) to guess your error rate in the wild . EOQ this might be a good heuristic in many cases for first exploratory experiments . but you should never rely on it in the end . overfitting can be controlled nicely by means of model selection instead . EOA 
 how do you determine whether you're overfitting when using random forest and other tree models ? : machinelearning tune your hyperparameters using your cross-val set ( NUM % ) , then use your test set ( NUM % ) to guess your error rate in the wild . EOQ i see overfitting as memorization . when using rf you have out-of-bag error rates ( training error rates ) . we should do cv , since it estimates how well our model will generalize to new data ( what we are most interested in ) . when you think you have too many features , i'd first try a simple sparse linear regression ( like logistic regression ) , and compare cv scores ( use a model to fit the data , don't fit the data to your pet algo ) . leakage may be a source of overfit . too many variables-rf usually causes underfit . it's actually pretty hard to overfit with rf's , since ensembling and bagging reduces overfit . EOA 
 how to apply machine learning to chemistry ? : machinelearning you may want to check out quantitative structure-activity relationships ( qsar ) . essentially , the properties of a chemical compound ( physical properties such as boiling/melting points , biological properties such as toxicity etc. ) are a function of its structure . your goal should be to collect a dataset ( depending on the complexity of the endpoint , already NUM compounds might do ) , and analyze it using typical ml methods . what do you think , how is the boiling point of normal chain alcohols ( methanol , ethanol, propanol , etc. ) related to the number of carbon atoms in the chain ? EOQ i don't know what's your context but i actually got to know machine learning when looking at chemistry journal papers . i am currently doing electro spinning . this is a process of making a certain polymer ( plastic ) by using a high voltage to generate plastic fibers nanometers wide. however this experiment is extremely difficult to carry out because many things can go wrong . you have to optimize NUM ) polymer concentration NUM ) surface tension NUM )voltage NUM ) distance NUM ) viscosity NUM ) temperature NUM )humidity there are about a few more that seems to escape my head but whatever it is it is a regression nightmare as all of them interact with each other(variables) when adjusted . there are some papers over the last NUM years that used ann and genetic algorithm to optimize this process . some journals said that the total possible combinations ranges to the millions and it's simply not possible to perform all of them . hence a computer is used to quicken the process . i'm not too sure what you can do in chemistry , perhaps synthetic chemistry may be of use ? i'm new to machine learning and i'm under the perception that machine learning is best used for optimization . hence you can find a place in chemistry that requires theoretical optimization that can be translated to real world experiments . EOA 
 how to apply machine learning to chemistry ? : machinelearning you may want to check out quantitative structure-activity relationships ( qsar ) . essentially , the properties of a chemical compound ( physical properties such as boiling/melting points , biological properties such as toxicity etc. ) are a function of its structure . your goal should be to collect a dataset ( depending on the complexity of the endpoint , already NUM compounds might do ) , and analyze it using typical ml methods . what do you think , how is the boiling point of normal chain alcohols ( methanol , ethanol, propanol , etc. ) related to the number of carbon atoms in the chain ? EOQ despite the fact that chem is not my specialty and that i could definitely use some brushing up on the subject , i'll chime in since no one else is . get more specific ; applied to chemistry in what way ? what type of chem ? what's the goal ? depending on these things you'll likely need to program or find programs that code as inputs the variety of known constraints governing chemical interactions . is there a biological target site you'd like to investigate ? what are its properties . as a high level example , the point of a programmed neural net might be the likelihood of action of a molecule on a target site trained on that site and molecules with known interactions . EOA 
 how to apply machine learning to chemistry ? : machinelearning you may want to check out quantitative structure-activity relationships ( qsar ) . essentially , the properties of a chemical compound ( physical properties such as boiling/melting points , biological properties such as toxicity etc. ) are a function of its structure . your goal should be to collect a dataset ( depending on the complexity of the endpoint , already NUM compounds might do ) , and analyze it using typical ml methods . what do you think , how is the boiling point of normal chain alcohols ( methanol , ethanol, propanol , etc. ) related to the number of carbon atoms in the chain ? EOQ there are several examples of applied ml in chemistry ( as well as biological sciences ) . how about this one ? URL EOA 
 how to apply machine learning to chemistry ? : machinelearning you may want to check out quantitative structure-activity relationships ( qsar ) . essentially , the properties of a chemical compound ( physical properties such as boiling/melting points , biological properties such as toxicity etc. ) are a function of its structure . your goal should be to collect a dataset ( depending on the complexity of the endpoint , already NUM compounds might do ) , and analyze it using typical ml methods . what do you think , how is the boiling point of normal chain alcohols ( methanol , ethanol, propanol , etc. ) related to the number of carbon atoms in the chain ? EOQ several domains in chemistry apply ml on a routine basis . for example qsar/qspr , which stands for quantitative structure activity/property relationships tries to find a mapping between the molecular structure , for example functional groups counts , and a target property , e.g. biological activity or a property like boiling point or homo/lumo gap . from the ml side , i have seen all standard and non-standard methods starting from simple linear models to svms , rfs, anns being used . one of the challenges in using ml in chemistry is to choose the right features/descriptors for your problem . this is an entire sub-discipline and requires some knowledge to ensure your features match the physical reality on the molecular level . sophisticated ml techniques can be outperformed by linear regression and well-engineered features on certain problems . if you are a bit more concrete in what you want to do , i can maybe point you to something more specific . EOA 
 how to apply machine learning to chemistry ? : machinelearning you may want to check out quantitative structure-activity relationships ( qsar ) . essentially , the properties of a chemical compound ( physical properties such as boiling/melting points , biological properties such as toxicity etc. ) are a function of its structure . your goal should be to collect a dataset ( depending on the complexity of the endpoint , already NUM compounds might do ) , and analyze it using typical ml methods . what do you think , how is the boiling point of normal chain alcohols ( methanol , ethanol, propanol , etc. ) related to the number of carbon atoms in the chain ? EOQ what if i'm interested in computational drug discovery and design ? EOA 
 custom dictionary creation by training on a corpus as the dictionary input for standard mispelling checker ? : machinelearning this sounds like scanning in all words in a corpus and storing them in a hash table . checking if the current word is in our hash table . if not then we start a levenstein distance comparison between all words and your misspelled one and return a list of closest words . its quick because you don't have to spend too much time writing the code for this . its dirty because it omits any semantic or contextual factors and looks blindly at the arrangement of characters . however you can use this as a basis for something more complicated . the next interesting step would be to build a table that relies on something like a bag of words model . EOQ you could use a vp tree maybe . EOA 
 custom dictionary creation by training on a corpus as the dictionary input for standard mispelling checker ? : machinelearning this sounds like scanning in all words in a corpus and storing them in a hash table . checking if the current word is in our hash table . if not then we start a levenstein distance comparison between all words and your misspelled one and return a list of closest words . its quick because you don't have to spend too much time writing the code for this . its dirty because it omits any semantic or contextual factors and looks blindly at the arrangement of characters . however you can use this as a basis for something more complicated . the next interesting step would be to build a table that relies on something like a bag of words model . EOQ correct spelling is usually defined as the one from a popular dictionary and words only really fully exist , if they are listed in there . now you have a machine telling others if the word exists and if they spelled correctly . you could say that language is a process and changes constantly so a machine that maybe analyzes statistical trends could be faster in generating a more modern dictionary with all the newest stuff like tl;dr. but how do you decide , which words you add to your large dictionary and which not ? an interesting application might be to check for correct spelling dependent on the actual context (e.g. loose-lose , your-you're). EOA 
 custom dictionary creation by training on a corpus as the dictionary input for standard mispelling checker ? : machinelearning this sounds like scanning in all words in a corpus and storing them in a hash table . checking if the current word is in our hash table . if not then we start a levenstein distance comparison between all words and your misspelled one and return a list of closest words . its quick because you don't have to spend too much time writing the code for this . its dirty because it omits any semantic or contextual factors and looks blindly at the arrangement of characters . however you can use this as a basis for something more complicated . the next interesting step would be to build a table that relies on something like a bag of words model . EOQ you may be interested in this article : URL how to write a spelling corrector by peter norvig . the dictionary used is comprised of project gutenberg and wiktionary documents and has about NUM million unique words . quick and elegant . look at urban dictionary if you want to capture slang . EOA 
 finally have a k20 server to start deep learning prototyping and research ! but which framework to use ? : machinelearning why not mxnet ? URL it natively supports python/java/c-/julia/go and javascript if you want EOQ does mxnet provide pre-trained models ( like model zoo of caffe ) ? EOA 
 finally have a k20 server to start deep learning prototyping and research ! but which framework to use ? : machinelearning why not mxnet ? URL it natively supports python/java/c-/julia/go and javascript if you want EOQ mxnet provides tools that convert all caffe pretrained models to mxnet URL EOA 
 finally have a k20 server to start deep learning prototyping and research ! but which framework to use ? : machinelearning why not mxnet ? URL it natively supports python/java/c-/julia/go and javascript if you want EOQ URL EOA 
 finally have a k20 server to start deep learning prototyping and research ! but which framework to use ? : machinelearning why not mxnet ? URL it natively supports python/java/c-/julia/go and javascript if you want EOQ i'm in the process of switching from keras/theano to torch , so i'm gonna recommend torch . of them , keras is the easiest to use and get started in . but it can be a bit limiting because if the package author doesn't believe in something (e.g., restricted boltzmann machines , pre-training), keras won't be setup for it . one nice thing about keras is that it has really good support for multiple inputs and outputs . lasagne is basically keras-lite. its easier to extend then keras , but you have to learn more theano and you can't use tensorflow as a backend . ( the reason this matters is that a lot of the work in building a neural net is monitoring things like the size of updates , whether some neurons have become inactive , what's happening with weights and losses at different layers , etc., and tensorflow has visualization tools for all of that . its also a lot easier to extend than theano . but it won't work with a gpu on mac os x. ) torch is far more complete than any of the other libraries . it has more loss functions , more activations , etc. etc . a lot more . the fb extensions to torch , fbcnn, have the only properly-implemented embedding class of any of the frameworks . ( the others update every weight on every batch , which creates a lot of training problems if the data is sparse. ) fbcnn also has a working hierarchicalsoftmax class . ( actually , tensorflow has a whole softmax-loss framework that i haven't played with , that may offer hierarchical-softmax functionality , but it isn't made available through any frameworks. ) the downsides of torch are that its a pain in the butt to install and keep up-to-date , its implemented in lua ( for no discernible reason ) , and fbcnn won't currently install on mac os x . EOA 
 finally have a k20 server to start deep learning prototyping and research ! but which framework to use ? : machinelearning why not mxnet ? URL it natively supports python/java/c-/julia/go and javascript if you want EOQ i agree . i am also hesitant in using torch because of a new scripting language ( i am familiar with python ) but would really want something flexible . does torch provide pre-trained models ? or can convert from caffe ? EOA 
 finally have a k20 server to start deep learning prototyping and research ! but which framework to use ? : machinelearning why not mxnet ? URL it natively supports python/java/c-/julia/go and javascript if you want EOQ torch has more pre-trained models than anything else . there's a package on github for converting caffe to torch . and i agree with you , i have the same reaction why in the heck did fb decide to implement this in lua of all g-dforsaken languages with no reason to exist . EOA 
 finally have a k20 server to start deep learning prototyping and research ! but which framework to use ? : machinelearning why not mxnet ? URL it natively supports python/java/c-/julia/go and javascript if you want EOQ here's another comparison : URL it's fairly biased in favor of torch , and the star ratings are subjective but the points are valid when weighted by your own needs . EOA 
 what do i need to build apps with tensorflow ? : machinelearning you need a gpu . cheapest worth buying is gtx970 , about $300 . you should have at least NUM gb ram , cpu is not that critical . i'd ballpark $700 if you build it yourself and buy all parts on sale . EOQ wow that's better than the graphics card i use for gaming . EOA 
 what do i need to build apps with tensorflow ? : machinelearning you need a gpu . cheapest worth buying is gtx970 , about $300 . you should have at least NUM gb ram , cpu is not that critical . i'd ballpark $700 if you build it yourself and buy all parts on sale . EOQ you can pick up a used gtx580 on ebay for under $100 . it computes faster than cards up to NUM x the price for some reason . EOA 
 what do i need to build apps with tensorflow ? : machinelearning you need a gpu . cheapest worth buying is gtx970 , about $300 . you should have at least NUM gb ram , cpu is not that critical . i'd ballpark $700 if you build it yourself and buy all parts on sale . EOQ it has tiny memory , compute capability NUM which means most modern frameworks won't function on it . EOA 
 what do i need to build apps with tensorflow ? : machinelearning you need a gpu . cheapest worth buying is gtx970 , about $300 . you should have at least NUM gb ram , cpu is not that critical . i'd ballpark $700 if you build it yourself and buy all parts on sale . EOQ would you be able to use aws ? EOA 
 what do i need to build apps with tensorflow ? : machinelearning you need a gpu . cheapest worth buying is gtx970 , about $300 . you should have at least NUM gb ram , cpu is not that critical . i'd ballpark $700 if you build it yourself and buy all parts on sale . EOQ amazon web services ? i hadn't considered it . EOA 
 what do i need to build apps with tensorflow ? : machinelearning you need a gpu . cheapest worth buying is gtx970 , about $300 . you should have at least NUM gb ram , cpu is not that critical . i'd ballpark $700 if you build it yourself and buy all parts on sale . EOQ sorry for the delay . i dont see why not though . if youre running ubuntu , and training based off the output from pygame , i would think it would work . may be worth trying to get pygame to run on a free tier of aws , and if things work upgrading so you can train a cnn EOA 
 what do i need to build apps with tensorflow ? : machinelearning you need a gpu . cheapest worth buying is gtx970 , about $300 . you should have at least NUM gb ram , cpu is not that critical . i'd ballpark $700 if you build it yourself and buy all parts on sale . EOQ would i be able to do a real time simulation of pong using amazon web services ? EOA 
 what is the difference between a fully-connected and convolutional neural network ? : machinelearning great explanation , but i want to suggest that convnets make sense ( as in , work ) even in cases where you don't interpret the data as spatial . it has been used quite successfully in sentence classification as seen here : yoon kim , NUM ( arxiv ) EOQ i'd argue that it's quite natural to think of sequence data , such as sentences , as being spatial , even if it's only a NUM-d space . spatial locality in this case of course corresponds to nearby elements in the sequence ( i.e. consecutive/nearby words in the sentence ) . EOA 
 what is the difference between a fully-connected and convolutional neural network ? : machinelearning great explanation , but i want to suggest that convnets make sense ( as in , work ) even in cases where you don't interpret the data as spatial . it has been used quite successfully in sentence classification as seen here : yoon kim , NUM ( arxiv ) EOQ <a href-URL EOA 
 what is the difference between a fully-connected and convolutional neural network ? : machinelearning great explanation , but i want to suggest that convnets make sense ( as in , work ) even in cases where you don't interpret the data as spatial . it has been used quite successfully in sentence classification as seen here : yoon kim , NUM ( arxiv ) EOQ there is no formal difference . fully connected layer us a convolutional layer with kernel size equal to input size. common convolutional architecture however use most of convolutional layers with kernel spatial size strictly less then spatial size of the input . unshared weights ( unlike shared weights ) architecture use different kernels for different spatial locations . EOA 
 help create a list of machine learning acronyms : machinelearning yaloda-yet another list of dumb acryonyms EOQ ha do you know fo another list ? EOA 
 help create a list of machine learning acronyms : machinelearning yaloda-yet another list of dumb acryonyms EOQ i'm reading through a lot of papers on advanced genetic algorithms so i'll add them as i find them . what are you planning on doing with this list ? EOA 
 help create a list of machine learning acronyms : machinelearning yaloda-yet another list of dumb acryonyms EOQ it's purely a learning aid . primarily , i find it useful to gauge my level of knowledge . for example , you can learn about cnn but you might wonder what other kinds of nn are there ? seeing the abbreviations for other nn might help you read some specific things about them to get a feel for what you know , what you don't know , and where you should start reading next . EOA 
 help create a list of machine learning acronyms : machinelearning yaloda-yet another list of dumb acryonyms EOQ how is anyone possibly going to find this easier to use than google ? EOA 
 help create a list of machine learning acronyms : machinelearning yaloda-yet another list of dumb acryonyms EOQ read-only version published here for easier referencing/sharing : URL EOA 
 help create a list of machine learning acronyms : machinelearning yaloda-yet another list of dumb acryonyms EOQ do we really need so many acronyms ? in my experience a culture of acronyms makes a field less accessible and friendly to lay people . i prefer to use full names then define a convenient acronym temporarily for the situation . this largely came out of the fact that i used to do a lot of work both with neural networks and nearest neighbors . both sides have claimed nn :( EOA 
 help create a list of machine learning acronyms : machinelearning yaloda-yet another list of dumb acryonyms EOQ when you read papers , blog entries , or articles ( in domain specific publications ) they tend to throw out a lot of acronyms . i don't know if there is a way to avoid this , it seems pretty inevitable . EOA 
 help create a list of machine learning acronyms : machinelearning yaloda-yet another list of dumb acryonyms EOQ of course , but they really should define the acronym before using it . if they aren't , they should be encouraged to from within the community . EOA 
 help create a list of machine learning acronyms : machinelearning yaloda-yet another list of dumb acryonyms EOQ ahh i see what youre saying . yeah, this is true , but is not done enough ( hence why i created the list ) . youre right though , people should be more rigorous about defining the acronyms they use at least once . EOA 
 deep learning libraries with inbuilt ctc lossfunction ? : machinelearning here's a ctc implementation i wrote a while ago in pure theano , so you should be able to use it in any theano framework : URL that said , you might also want to look into using an attention mechanism for alignment , which imo is significantly easier to implement / debug than ctc , supported out-of-the-box by most deep learning frameworks , and performs almost as well . EOQ if you want minibatches i have a theano version , though it may need an additional op/fix for gpueye to run on gpu : URL EOA 
 deep learning libraries with inbuilt ctc lossfunction ? : machinelearning here's a ctc implementation i wrote a while ago in pure theano , so you should be able to use it in any theano framework : URL that said , you might also want to look into using an attention mechanism for alignment , which imo is significantly easier to implement / debug than ctc , supported out-of-the-box by most deep learning frameworks , and performs almost as well . EOQ for asr there is eesen , based on kaldi . EOA 
 deep learning libraries with inbuilt ctc lossfunction ? : machinelearning here's a ctc implementation i wrote a while ago in pure theano , so you should be able to use it in any theano framework : URL that said , you might also want to look into using an attention mechanism for alignment , which imo is significantly easier to implement / debug than ctc , supported out-of-the-box by most deep learning frameworks , and performs almost as well . EOQ chainer has one built in EOA 
 deep learning libraries with inbuilt ctc lossfunction ? : machinelearning here's a ctc implementation i wrote a while ago in pure theano , so you should be able to use it in any theano framework : URL that said , you might also want to look into using an attention mechanism for alignment , which imo is significantly easier to implement / debug than ctc , supported out-of-the-box by most deep learning frameworks , and performs almost as well . EOQ there's an issue on tensorflow github about beam search where a tf maintainer mentions that they'll have an implementation of ctc available soon . EOA 
 deep learning libraries with inbuilt ctc lossfunction ? : machinelearning here's a ctc implementation i wrote a while ago in pure theano , so you should be able to use it in any theano framework : URL that said , you might also want to look into using an attention mechanism for alignment , which imo is significantly easier to implement / debug than ctc , supported out-of-the-box by most deep learning frameworks , and performs almost as well . EOQ baidu just open sourced their cpu/gpu ctc implementation : URL it is released as a c-library along with bindings for torch . integration into other frameworks should hopefully be straightforward . EOA 
 want to contribute to open source projects related to machine learning/data science . : machinelearning compiling URL EOA 
 want to contribute to open source projects related to machine learning/data science . : machinelearning compiling EOA 
 want to contribute to open source projects related to machine learning/data science . : machinelearning compiling EOA 
 want to contribute to open source projects related to machine learning/data science . : machinelearning compiling all our major contributors-@agibsonccc , @nyghtowl, @alexdblack , @raver119 et al-and about NUM users are there , so it's a good place to get questions answered . you might also want to look at the scala wrapper we wrote for our scientific computing framework , nd4j, or n-dimensional arrays for java . URL EOA 
 want to contribute to open source projects related to machine learning/data science . : machinelearning compiling EOA 
 adversarial examples : ensemblea as antidote ? : machinelearning there is a nice post by ian goodfellow myth : an attacker must have access to the model to generate adversarial examples . fact : adversarial examples generalize across models trained to perform the same task , even if those models have different architectures and were trained on a different training set . this means an attacker can train their own model , generate adversarial examples against it , and then deploy those adversarial examples against a model they do not have access to . EOQ that was only shown on mnist though . i don't think anyone has demonstrated e.g. visually indistinguishable fooling images generated on googlenet that also work against vgg . EOA 
 adversarial examples : ensemblea as antidote ? : machinelearning there is a nice post by ian goodfellow myth : an attacker must have access to the model to generate adversarial examples . fact : adversarial examples generalize across models trained to perform the same task , even if those models have different architectures and were trained on a different training set . this means an attacker can train their own model , generate adversarial examples against it , and then deploy those adversarial examples against a model they do not have access to . EOQ /u/vodkagoodmeatrotten has a cite in a post lower on this thread that suggests that they have demonstrated that . EOA 
 adversarial examples : ensemblea as antidote ? : machinelearning there is a nice post by ian goodfellow myth : an attacker must have access to the model to generate adversarial examples . fact : adversarial examples generalize across models trained to perform the same task , even if those models have different architectures and were trained on a different training set . this means an attacker can train their own model , generate adversarial examples against it , and then deploy those adversarial examples against a model they do not have access to . EOQ URL EOA 
 adversarial examples : ensemblea as antidote ? : machinelearning there is a nice post by ian goodfellow myth : an attacker must have access to the model to generate adversarial examples . fact : adversarial examples generalize across models trained to perform the same task , even if those models have different architectures and were trained on a different training set . this means an attacker can train their own model , generate adversarial examples against it , and then deploy those adversarial examples against a model they do not have access to . EOQ thanks for the link . the fooling method works , according to karpathy 's blog , because the perturbation vector ( the diff between original and adversarial image ) is crafted so to tweak the weights in the direction of increasing the score of the false tagret and/or reducing the score of the original target . with this insight , how can be explained the generalization of the adversial example to different instance of the net , or even different nodels ? does this mean that ( a sensible part of ) the weights in the different networks have the same gradient sign in relation to the same target objects ? EOA 
 adversarial examples : ensemblea as antidote ? : machinelearning there is a nice post by ian goodfellow myth : an attacker must have access to the model to generate adversarial examples . fact : adversarial examples generalize across models trained to perform the same task , even if those models have different architectures and were trained on a different training set . this means an attacker can train their own model , generate adversarial examples against it , and then deploy those adversarial examples against a model they do not have access to . EOQ that's a lie . adversarial examples overfit noise. you can't find adversarial examples for well regularised models for example . EOA 
 adversarial examples : ensemblea as antidote ? : machinelearning there is a nice post by ian goodfellow myth : an attacker must have access to the model to generate adversarial examples . fact : adversarial examples generalize across models trained to perform the same task , even if those models have different architectures and were trained on a different training set . this means an attacker can train their own model , generate adversarial examples against it , and then deploy those adversarial examples against a model they do not have access to . EOQ regarding regularization , karpathy says : intuitively, it seems that higher regularization leads to smaller weights , which means that one must change the image more dramatically to change the score by some amount . so it seems that regularization makes the work of the attacker more difficult , but it is a quantitative difference , not a qualitative one ; the basic concept still applies . what is really surprising is that an adversarial example built for one network instance works also for another one . indeed it is not exactly like this , in the original paper they report a table in which is shown that adversarial example have more than noise probability to fool a second network , but they are far to work in NUM % of cases as in the network they have been built for . also another point that is not clarified is if the false target is the same for all the networks . suppose an adversarial example out of a banana picture is built to fool a specific network into seeing an apple , does the same adversarial example used on a different network fool it to seeing an apple too ? or perhaps another object ( different form a banana ) ? this is a sensible information imo , but i cannot find in the paper . EOA 
 adversarial examples : ensemblea as antidote ? : machinelearning there is a nice post by ian goodfellow myth : an attacker must have access to the model to generate adversarial examples . fact : adversarial examples generalize across models trained to perform the same task , even if those models have different architectures and were trained on a different training set . this means an attacker can train their own model , generate adversarial examples against it , and then deploy those adversarial examples against a model they do not have access to . EOQ goodfellow et al . show that adversarial examples are due to linearity and high-dimensionallity . the regularizer used by karpathy reduces the dimensionality . EOA 
 adversarial examples : ensemblea as antidote ? : machinelearning there is a nice post by ian goodfellow myth : an attacker must have access to the model to generate adversarial examples . fact : adversarial examples generalize across models trained to perform the same task , even if those models have different architectures and were trained on a different training set . this means an attacker can train their own model , generate adversarial examples against it , and then deploy those adversarial examples against a model they do not have access to . EOQ yes , an ensemble of nets is prone to adversarial example attacks . pretty amazing imo . URL intriguing properties of neural networks in addition , the specific nature of these perturbations is not a random artifact of learning : the same perturbation can cause a different network , that was trained on a different subset of the dataset , to misclassify the same input . for all the networks we studied ( mnist , quocnet [10 ] , alexnet [9]) , for each sample , we have always managed to generate very close , visually hard to distinguish , adversarial examples that are misclassified by the original network cross model generalization : a relatively large fraction of examples will be misclassified by networks trained from scratch with different hyper-parameters ( number of layers , regularization or initial weights ) . cross training-set generalization a relatively large fraction of examples will be misclassified by networks trained from scratch on a disjoint training set the above observations suggest that adversarial examples are somewhat universal and not just the results of overfitting to a particular model or to the specific selection of the training set . EOA 
 deep residual learning : the bottleneck : machinelearning i agree , a NUM x1 convolution with stride NUM is completely pointless . the only thing that makes sense to me is to have strides ( NUM , NUM ) in convlayer2 . EOQ i asked this previously . URL EOA 
 deep residual learning : the bottleneck : machinelearning i agree , a NUM x1 convolution with stride NUM is completely pointless . the only thing that makes sense to me is to have strides ( NUM , NUM ) in convlayer2 . EOQ its also in figure NUM . EOA 
 deep residual learning : the bottleneck : machinelearning i agree , a NUM x1 convolution with stride NUM is completely pointless . the only thing that makes sense to me is to have strides ( NUM , NUM ) in convlayer2 . EOQ how do you count flops in theano ? EOA 
 deep residual learning : the bottleneck : machinelearning i agree , a NUM x1 convolution with stride NUM is completely pointless . the only thing that makes sense to me is to have strides ( NUM , NUM ) in convlayer2 . EOQ afaik , theano doesn't offer any way to calculate flops . instead, you just estimate . for example , multiplying a m-n matrix with a n-p matrix takes mp(2n-1) flops . EOA 
 deep residual learning : the bottleneck : machinelearning i agree , a NUM x1 convolution with stride NUM is completely pointless . the only thing that makes sense to me is to have strides ( NUM , NUM ) in convlayer2 . EOQ if you look at figure NUM you see that only a few layers have a stride of NUM , i would agree that the stride happens in the ( NUM ,3 ) layers . EOA 
 deep residual learning : the bottleneck : machinelearning i agree , a NUM x1 convolution with stride NUM is completely pointless . the only thing that makes sense to me is to have strides ( NUM , NUM ) in convlayer2 . EOQ figure NUM shows only the NUM layer modules , not the NUM layer modules that op is talking about that used in the NUM and NUM layer networks . EOA 
 deep residual learning : the bottleneck : machinelearning i agree , a NUM x1 convolution with stride NUM is completely pointless . the only thing that makes sense to me is to have strides ( NUM , NUM ) in convlayer2 . EOQ kaiming he was as nice to share after i emailed him : in all experiments in the paper , the stride-2 operation is in the first NUM x1 conv layer when downsampling . this might not be the best choice , as it wastes some computations of the preceding block . for example , using stride-2 in the first NUM x1 conv in the first block of conv3 is equivalent to using stride-2 in the NUM x3 conv in the last block of conv2 . so i feel applying stride-2 to either the first NUM x1 or the NUM x3 conv should work . i just kept it âas isâ , because we do not have enough resources to investigate every choice. EOA 
 deep residual learning : the bottleneck : machinelearning i agree , a NUM x1 convolution with stride NUM is completely pointless . the only thing that makes sense to me is to have strides ( NUM , NUM ) in convlayer2 . EOQ yes , it was done in convlayer1 . you can also find the NUM layers resnet's full architecture from their iccv15 ppt , ( page NUM ~11 ) : URL EOA 
 identical network converging in theano but saturating in tensorflow ? : machinelearning some suggestions : -to make sure initializations are the same , just generate the matrices on one platform and load the initialized matrices in the other ( in tensorflow you can pass a numpy object to initialize any parameter ) -can you try another activation function ? softsign isn't all that common ... -how do the losses compare before starting ? you should also try to compare the gradients if losses are the same . EOQ thanks for the response . i did compare the initializations via manual examination . they did seem identical ( within precision limits ) , though that's a good idea about just loading in the matrices actually i started with plain sigmoids , and switched to softsign after reading this paper as above , the losses are similar ( not identical , but i'm assuming that's due to the different numerical libraries ) . i didn't compare the gradients yet , but i assume they aren't too different based on the roughly similar loss improvements in the first couple of iterations EOA 
 identical network converging in theano but saturating in tensorflow ? : machinelearning some suggestions : -to make sure initializations are the same , just generate the matrices on one platform and load the initialized matrices in the other ( in tensorflow you can pass a numpy object to initialize any parameter ) -can you try another activation function ? softsign isn't all that common ... -how do the losses compare before starting ? you should also try to compare the gradients if losses are the same . EOQ neither tensorflow nor theano claim ieee NUM compliance , thus it's unreasonable to expect identical results . floats just are that i'd suggest to output the gradients to make sure it's not a numerical stability issue . theano does some optimizations to prevent that . EOA 
 identical network converging in theano but saturating in tensorflow ? : machinelearning some suggestions : -to make sure initializations are the same , just generate the matrices on one platform and load the initialized matrices in the other ( in tensorflow you can pass a numpy object to initialize any parameter ) -can you try another activation function ? softsign isn't all that common ... -how do the losses compare before starting ? you should also try to compare the gradients if losses are the same . EOQ hi , thanks for responding . i followed the standard installation steps for theano and tensorflow . theano mentions using blas , unsure about tf . though... would that be enough to cause such a difference in results ? i assume an inferior numerical library would have been picked up by the community right away . yup , both are using float32 for input data and graph variables yup , same pre-processing ( none ! unless theano/tf does some automatic normalization by default ) , both reading from the same raw data files yup , same numpy prng (using numpy.random.randomstate). verified by initializing under both theano/tf and examining the initial weights it's really puzzling . i assumed under similar conditions theano and tf should produce similar results ( factoring in the possibly different numerical libraries ) . what makes it even worse is that expanding the network seems to have little effect in tensorflow . the data has spatial relationships so i actually started off using a convolutional nn . loss values still saturated ~40 . has anyone else tried using tf for regression ? EOA 
 [beginner] which of the math courses in this list would be useful for machine learning ? : machinelearning thank you so much ! i'll definitely be taking linear programming then . EOQ you should definitely take a linear programming and optimization class . i bet a word convex will sound a lot in this class , though not stated in the title . other classes ( besides that you've already taken ) are less useful in ml ( except maybe first part of numerical analysis NUM : linear and non-linear systems of equations ) . graph theory might be useful , since it's a workhorse of most of computer science , which ml is a subfield of . EOA 
 [beginner] which of the math courses in this list would be useful for machine learning ? : machinelearning thank you so much ! i'll definitely be taking linear programming then . EOQ i have to take two NUM-level courses , so i guess one of them will be graph theory . how useful would abstract algebra be ? i have to take abstract algebra NUM as it is a requirement , but what about ii ? do you recommend i take it ? EOA 
 [beginner] which of the math courses in this list would be useful for machine learning ? : machinelearning thank you so much ! i'll definitely be taking linear programming then . EOQ from the mainstream point of view , i find it pretty much useless . the only useful algebra in ml is linear algebra . group theory is good for cryptography , galois theory is good for error-correcting codes , but i didn't see either of them extensively applied in ml . now , if you want to do research , there is some work on bringing group theory to machine learning . though not mainstream either . EOA 
 summer internships : machinelearning we are looking for interns if you are interested in small startups . send resume to diego at algorithmia dot com EOQ are you interested in taking on self taught machine learners or only cs graduates ? EOA 
 summer internships : machinelearning we are looking for interns if you are interested in small startups . send resume to diego at algorithmia dot com EOQ i hope their only requirement is being a beast at ml . EOA 
 summer internships : machinelearning we are looking for interns if you are interested in small startups . send resume to diego at algorithmia dot com EOQ self taught isnt a problem if you can prove you know what you are doing . for interns we do prefer ms or phd candidates . sorry but only us based for now . EOA 
 panda challenge for cnn : machinelearning NUM % accuracy someone submit this to arxiv URL EOQ smells like genuine human intelligence EOA 
 panda challenge for cnn : machinelearning NUM % accuracy someone submit this to arxiv URL EOQ what's the title of this manuscript ? i didn't find it in arxiv . thanks. EOA 
 finished my first ml project , an evolutionary algorithm engine. any advice ? : machinelearning it would be interesting if you can visualise your 'nature simulation' of this library in a graphical way . are there any other demos or applications that can be written to use this engine ? EOQ i designed it to be a tool that can be used for any application . so yes other demos/applications can be written , but so far i've only implemented the nature simulation as a simple way of testing the engine. i'll definitely experiment with visualization of the information though . EOA 
 any recommendations for an easy to use regression supervised learner ( numeric inputs and outputs ) in java ? : machinelearning there's the olsmultiplelinearregression class in the apache commons math library . EOQ thanks , will take a look EOA 
 any recommendations for an easy to use regression supervised learner ( numeric inputs and outputs ) in java ? : machinelearning there's the olsmultiplelinearregression class in the apache commons math library . EOQ URL EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ interesting . what you wrote sounds sensible . nevertheless right now i am running the following experiment : you have a dot on the line , which has speed and acceleration . your action value is acceleration . you reward is negatove distance to the middle of the line . even such a simple problem does not converge ;-( EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ i tried a pendulum swing up task with low-dimensional inputs and couldn't get it to work either ! is it possible to take a look at your code ? i'm happy to share mine ; although it is very messy ! some important questions : what learning rates are you using for actor and critic ? what inputs do the actor and critic each receive ( distance , velocity, ... ) ? how many updates are you doing per replay on the actor and critic ? what kind of exploration noise are you using in the actor ? EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ totally , i push my code on a branch : URL it is based on my code for discrete deep q which by now i am quite confident works well . i have two notebooks using the continuous controller-double pendulum and trivial square . neither works . in particular for trivial.square i wrote a very simple hand coded controller which does the job very well and what network learns is far inferior . let me know if you have any questions . also i am curious to see your code . EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ i'm having a look over it now-beautifully written by the way . i'll write my own version of the NUM-d particle centerer task , then we can compare how we each wrote it independently to check for bugs . give me a day or so EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ thank you ! yeah, no rush , i'm working on my masters thesis this month , so i won't spend much time on implementing this probably , but let me know if you have something . if you prefer to communicate over email , so that we don't spam reddit write me at my email szymon.sidor@gmail.com EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ hi , i've also tried to implement continuous case based on your doublependulum notebook :) and only now i've noticed that you have another branch with the implementation . also i found some other implementations by one author ( one in theano URL , another in tensorflow URL ) , though there were some differences from the original paper ( imo ) , which i described here URL . maybe you'll find it useful to compare with your implementation , though don't know whether it really works . EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ wow , that tensorflow code is really good . if i understand it correctly the idea is to take gradient for the actor in the on-policy fashion i.e. maximize sum of rewards in a sequence of actions , while the critic is updated off-policy , just like in regular deepq . that sounds like there's some logic to it ;-) i will change my code at some point to incorporate that . edited . EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ are you talking about these lines ? # policy objective : maximize on-policy critic activations self.policy.objective-tf.reduce.mean(self.critic.on) # critic objective : minimize mse of off-policy q-value predictions q.errors-tf.square(self.critic.off-self.q.targets) self.critic.objective-tf.reduce.mean(q.errors) did you mean critic is updated off-policy ( not actor ) ? EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ yes EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ i'm looking at your code now ... don't you do the same ? # actor self.actor.action-tf.identity(self.actor(self.observation), name-actor.action) self.actor.score-self.critic([self.observation, self.actor.action]) actor.gradients-self.optimizer.compute.gradients(tf.reduce.mean(-self.actor.score), var.list-self.actor.variables()) # critic self.value.given.action-self.critic([self.observation, self.given.action]) temp.diff-self.value.given.action-self.future.reward self.critic.error-tf.reduce.mean(tf.square(temp.diff)) i mean , i see that he is doing a bit different , because his critic.off doesn't use actions from replay buffer ( given.action ) , but instead actions are calculated each time using current actor model-noise. but i would say that in both cases it goes off-policy . and it seems to me that it is more logical to use actions from the replay buffer . EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ well i am using a minibatch to update an actor no a contiguous sequence of transitions . i looked at the paper pseudocode again and they seem to be doing what i am doing though . do you know if the other code from github works ? i won't have a chance to run it today .. EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ hmm ... sorry, not sure i'm following you ... he also uses minibatches for training both actor and critic , doesn't he ? can you clarify where you see the difference ? training actor , critic or both ? i see only difference in training critic ... i didn't run his tensorflow code as is , but extracted/combined multiple pieces from there and adapted to my task , besides i changed places that i thought were not logical to me ( that i described in the issue ) . but it didn't converge for me . maybe because i did something wrong , or maybe because it didn't work originally . i actually tried to run his theano version ( as is ) . but didn't see any meaningful results . EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ well , i though about it and what i wrote before makes no sense , so i won't try to explain it further ;-) i also looked at the tf code and it's definitely doing something very similar to what i was doing . it would be good to understand if that code works at all before diving deep into how it's implemented though . it's the second paper by deepmind that seems very hard to reproduce , first being the ntm . EOA 
 deep q learning with continuous actions ( question about paper continuous control with deep reinforcement learning ) : machinelearning i'm also trying to implement something based on this paper it is my intuition too that we should minimize the negative of the critic score , and update only the actor variables . i have not got mine to converge to any meaningful strategy either , but i have not debugged the actor side yet . the issue i have with the paper is that equation NUM gives an expression for q(s,a), and then equation NUM is supposedly obtained by differentiating equation NUM wrt actor params , however equation NUM is a gradient of the actor function , not the q-value ... i resolved this by assuming 'using the chain rule' means that i should multiply the gradient of the actor function wrt actor params by the gradient of the q-value wrt actor output . in their previous paper URL they do explicitly mention the update rule for the actor parameters ( equation NUM ) , which is the the gradient of the q-value wrt actor params . what are your thoughts on the number of updates one should do on the actor and critic ; per replay ? the paper just says we should 'minimize the loss'-this could mean reducing the loss to some threshold , or just doing some number of steps . let me know if you agree with my analysis ; i think it will be helpful if we cooperate EOQ hey , if you're interested , there is a response from the author clarifying his results URL EOA 
 eli5: the reparameterization trick : machinelearning the trick part of the reparameterization trick is that you make the randomness an input to your model instead of something that happens inside it , which means you never need to differentiate with respect to sampling ( which you can't do ) . since the randomness is an input the whole network is deterministic , and you can differentiate the whole thing as normal . it is worth spending time understanding the aevb paper , the explanation there is very good if you take the time to unpack it . in particular , consider the following two ways of writing the objective in eq NUM ( where l-1 for simplicity ) : f(z) where z-g.phi(eps , x) and eps ~ p(eps) f(z) where z ~ p.phi(x) in the first version you can compute the gradient of f with respect to phi , because the sampling has been moved out of the way , but in the second version the sampling step blocks the gradient from z to phi . the second part of your question is trickier to answer because there are really two things going on in aevb that come together to make the setup make sense , it's not just a matter of applying the reparameterization trick . in aevb ( and all of its variants , including the papers you cite ) there are two forces acting on the sampling layer . one is the likelihood ( i.e. loss from the decoder p(x|z ) ) which tries to make the samples as deterministic as possible . the second is the kl term between the prior and the posterior ( i.e. encoder distribution ) , which tries to make the samples look like samples from the prior . competition between these two terms is what makes learning the variance of the distribution work , if you take away the kl term then the variance of the encoder will collapse . if you want to instead want to fix the variance and just learn the mean of the distribution then everything is dramatically simpler , and you don't need any of the variational machinery from aevb . in this setting you are just adding noise to the activations of your network and you deal with this in the backward pass by ignoring it . you can use the reparamterization trick to justify this ( which might be a good exercise to see if you understand why it works ) , but all the rest of the aevb machinery disappears . EOQ thanks m8 ! EOA 
 eli5: the reparameterization trick : machinelearning the trick part of the reparameterization trick is that you make the randomness an input to your model instead of something that happens inside it , which means you never need to differentiate with respect to sampling ( which you can't do ) . since the randomness is an input the whole network is deterministic , and you can differentiate the whole thing as normal . it is worth spending time understanding the aevb paper , the explanation there is very good if you take the time to unpack it . in particular , consider the following two ways of writing the objective in eq NUM ( where l-1 for simplicity ) : f(z) where z-g.phi(eps , x) and eps ~ p(eps) f(z) where z ~ p.phi(x) in the first version you can compute the gradient of f with respect to phi , because the sampling has been moved out of the way , but in the second version the sampling step blocks the gradient from z to phi . the second part of your question is trickier to answer because there are really two things going on in aevb that come together to make the setup make sense , it's not just a matter of applying the reparameterization trick . in aevb ( and all of its variants , including the papers you cite ) there are two forces acting on the sampling layer . one is the likelihood ( i.e. loss from the decoder p(x|z ) ) which tries to make the samples as deterministic as possible . the second is the kl term between the prior and the posterior ( i.e. encoder distribution ) , which tries to make the samples look like samples from the prior . competition between these two terms is what makes learning the variance of the distribution work , if you take away the kl term then the variance of the encoder will collapse . if you want to instead want to fix the variance and just learn the mean of the distribution then everything is dramatically simpler , and you don't need any of the variational machinery from aevb . in this setting you are just adding noise to the activations of your network and you deal with this in the backward pass by ignoring it . you can use the reparamterization trick to justify this ( which might be a good exercise to see if you understand why it works ) , but all the rest of the aevb machinery disappears . EOQ this might also be of interest for another explanation : URL EOA 
 massive deep learning : machinelearning NUM s of gpu's is something only the top labs have , and they all run their own internal libraries combined with popular open source software . mxnet has a lot of cool ideas with respect to multi-gpu training . for a decent cluster consisting of a number of gpus , it would be the best bet . see this EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ i think you are looking for /r/mlquestions or /r/mlclass , which already exist and are even mentioned in this subreddit's sidebar ! there have been other , similar subreddits as well , but they've been abandoned . even the ones mentioned above don't seem to get much traffic . apparently the community isn't large enough for two subreddits . at least that's the consensus when this was discussed in the past ( e.g. /r/mlquestions instead , as that still seems somewhat used . we (the mods ) are happy to help , e.g. by pinning an announcement and redirecting newbie-questions in the future . however , i also think that something like a regular beginner question thread might be more useful-then even people who aren't willing to subscribe to a beginner-subreddit can see the thread and might pop in to answer questions , and beginners . have an easier time finding it . however, the interest sort of vanished over time , and no-one was willing to pick up the slack . maybe we could've done more to publicize those threads back then . if someone volunteers to set them up ( past experience shows i'm not the guy for that job ) , he's got my support . lastly , for the downvote-problem i think /u/tehsandvich has hit the nail on its head : the problem is that the easy questions come up over and over again , with no-one bothering to using the search function before posting . which is why people downvote them . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ couldn't you configure automoderator to create a weekly thread for beginner questions ? i believe that the problem with the previous simple questions thread was that no one felt responsible for creating a new one . with automoderator this issue wouldn't exist . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ i think automoderator would be the best solution . there's even a script for it . URL EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ thanks for the head's up . if there is interest in a weekly question thread , then that's a really good way of doing it ! :) EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ thank you for your comment ... i use bacon reader so i never knew about the other subreddits !! EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ i started looking into ml for the first time today , and i am totally a beginner , but i completely agree with this . other subreddits i'm involved in have become monotonous with the same questions repeatedly asked because people don't think to do a quick reddit/google search . i hope this subreddit doesn't become like that so in a few months it'll still provide value to me . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ you're part of the problem : this subreddit doesn't exist to do your algebra for you . look at the sidebar topics . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ my question was related to ml the same way the backprop algorithm is related to ml even though it's NUM % about calculus . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ your question was asking someone to walk through a book derivation for you . that's not ml news , research or discussion . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ you keep saying for you as if asking for help is equivalent to delegating to others work you should do yourself . have you ever been a beginner ? either you haven't or you forgot what it was like . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ yes , educating yourself is your own responsibility . and this is not a subreddit for helping beginners . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ what's your definition of educating yourself ? going into google and and finding out how to do it ? well coming on reddit is just another resource for him to be able to learn it . if i was to explain it to him here it would be no different from him finding an explanation elsewhere . this is just another resource for learning in my opinion . if we don't help each other out then how do we advance and help out the next brightest machine learning experts , we all start somewhere so please quit being an ass . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ until google cracks ai , you're not annoying anyone by running a search . filling this subreddit with requests for answers to stupid questions is a great way to drive away those bright machine learning experts who actually hang out here . if you just keep your ignorant mouths shut and listen , you might learn something . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ the problem with questions on this subreddit is : half of the questions posted here are just extremely low quality . if a person doesn't show the slightest effort to come up with a solution for themselves , outlining them a solution is pointless because they won't manage to implement it anyway . moving them to a separate thread or a separate subreddit won't make these questions less pointless . i'm talking about the can you tell me real quick how i predict the stock market ? kind of questions . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ is this better : can you give me a highly detailed solution for predicting the stock market ? with code samples preferably ! :-) EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ that's also lazy . you need to at least google your idea and research any methods you'd find for predicting the stock market . once you do that , if you have trouble understanding some technicality that doesn't already have a question on stack exchange , you could reasonably ask a question here ( or stack exchange ) . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ personally , i feel less qualified than a lot of the posters here ( i don't have a degree in ml )-but i love it . i think something this sub does well is unapologetically filter out bad content . other subs succumb to memes or lowest-common denominator content , and their communities are worse off for it . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ personally i feel like most of the thoughtful questions ( where people actually bother to google in advance , and don't act like their pet theory is the answer to everything ) usually get answered . as for the other questions , down vote is good . that said , i wouldn't mind seeing a weekly 'dumb question' thread , to help the new and intimidated people feel more comfortable posting ... if it's a whole subreddit of such things , i probably won't read it ... EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ i think that it is a good idea , doing stupid things for fun and experiments out of curiosity is exactly what has driven science for centuries . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ how about trying a weekly beginner q & a thread that more experienced developers make an effort to upvote and reply to ? EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ not that the following is necessarily bad , but i was commenting ( just the other day ) how this subreddit has become something of an rss feed for deep learning arxiv posts ( just by another name ) ... i would love to see this thread's atmosphere move towards something that's a spiritual child of /r/python and /r/learnpython . that is , the thread has a community of people who are clearly passionate about ml , but also down to help beginners level themselves up . however, i'm not so sure the community here wants to encourage /r/learnpython-level questions , which is a shame ... EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ i like the idea , suggested at several points here , of having a one or two-weekly sticky post for newbie q & a . pros :-visible-not sure we have a big enough community to warrant a separate sub for just this ( although there is one )-more inclusive a newcomers to the community cons :-questions would not come up on reddit search ? EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ why not /r/askml like /r/askelectronics ? coincidentally, /r/machinelearning has a similar amount of users when compared to /r/electronics . EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ that is if we want to constrain ourselves that familiar format . do you like the way things are answered or discussed there ? does it lay out the project pretty well ? or is it more like a place to consult on the progress of your project ? EOA 
 [meta] this subreddit is overwhelming . : machinelearning the questions that people ask usually requires a simple , quick answer . a new thread being posted every time someone has a question leads to these questions filling up the frontage which overshadows the discussion of more technical material . this is still an issue though , there should be some way for beginners to ask for help without being downvoted for relative triviality . the problem with creating a new board is that the machine learning subreddit is already small as it is and any new beginner friendly board will quickly become stagnant . i think a better solution would be to have something equivalent of a moronic monday thread that /r/personalfinance has but even then i doubt enough questions would get asked . a stickied weekly thread would be more appropriate for this subreddit . EOQ yes , i think it is naive. just because people enjoy discussing ml research , doesn't mean they have any interest in helping rank beginners who are too lazy to find and read any of the thousands of tutorials and reference materials available for novices . EOA 
 interesting recent papers/videos/talks ? : machinelearning try going through recent ama : URL there is a lot links to research papers ... EOQ thanks i checked out some of those ( in fact it was doing that that inspired me to write this post ) . i guess i'm looking more for interesting videos to watch during down time...e.g. some recommendations from nips or some other recent workshop . i'll edit the post accordingly . EOA 
 book most similar to andrew ng's course ? : machinelearning which course are you talking about ? the coursera one ? if so , try andrew's stanford course : URL the lecture notes are essentially a textbook that is very easy to read and well-written . the homeworks are online so those can be your exercises . EOQ thanks , but i'm looking for an actual textbook . EOA 
 book most similar to andrew ng's course ? : machinelearning which course are you talking about ? the coursera one ? if so , try andrew's stanford course : URL the lecture notes are essentially a textbook that is very easy to read and well-written . the homeworks are online so those can be your exercises . EOQ it's not a whole book ( yet ) but it is an amazingly accessible explanation of backpropagation for programmers : andrej karpathy-hacker's guide to neural networks i empathize with your desire for the kind of course andrew taught . it was eye opening for me too , much more than the other courses . but what i would like to have even more than a course , though, is a collection of problems , with a gentle , gradually increasing curve of difficulty . the key is to have a gradation of difficulty that is matched to the average effort required to master the concepts . i think there are machine learning techniques to adjust a curriculum ( yes , found it , it's called bayesian knowledge tracing ) . if we had that we could gradually chip away at the conceptual framework and skill-set with targeted exercises that are not too difficult and yet not too shallow at every point in our learning process . EOA 
 book most similar to andrew ng's course ? : machinelearning which course are you talking about ? the coursera one ? if so , try andrew's stanford course : URL the lecture notes are essentially a textbook that is very easy to read and well-written . the homeworks are online so those can be your exercises . EOQ thanks for the karpathy recommendation . i think we're definitely on the same page here . EOA 
 book most similar to andrew ng's course ? : machinelearning which course are you talking about ? the coursera one ? if so , try andrew's stanford course : URL the lecture notes are essentially a textbook that is very easy to read and well-written . the homeworks are online so those can be your exercises . EOQ i have yet to encounter ml books with much in the way of exercises but you can access a couple of the most popular books online for free : an introduction to statistical learning the elements of statistical learning EOA 
 book most similar to andrew ng's course ? : machinelearning which course are you talking about ? the coursera one ? if so , try andrew's stanford course : URL the lecture notes are essentially a textbook that is very easy to read and well-written . the homeworks are online so those can be your exercises . EOQ thanks . i really like that intro book EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ maybe we can give it another shot ? i'd be very interested in participating ! EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ yeah , i'd be very interested too . EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ me three ! EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ i second the stickied idea . what also works well with local grad students is to get the list of members and then fifo for responsibility . so week NUM , the first person to sign up is the first to present a paper . all the weeks are locked in . people can trade up if they want but a set schedule makes it harder for the reading group to flake out . edit : oops. it's early . combined two posts . /u/mr.robot.elliot/ had the stickied idea EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ definitely EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ i don't know of any , but i'd be interested in joining one ( depending on the subject matter and definition of advanced ) . EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ i would be also interested ! but how shall we organize it ? perhaps sticked post(like that of ama) sort of setting for weekly paper or so might generate interest and the discussion can get thrive over time unlike previous tries . let me know if you have any other ideas . EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ i would also be interested . EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ i think we should avoid reading randomly selected papers . it's good to follow a schedule and cover a specific topic each week or so . depending on the group size , i guess the idea of one person presenting each week is more practical . i think one way to start is to follow the schedule of a advanced machine learning course . such as URL or URL . if not , we should come up with a NUM or NUM week schedule and cover readings for each week . please let us know of your thoughts/suggestions . EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ also interested EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ interested EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ interested EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ i was thinking of associating each paper with an eli5 post and save it for future reference for other redditors . it would give added incentive of competition and will let the ball rolling even for those who haven't read the papers yet ? what do you say guys ? EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ interested EOA 
 online reading groups for advanced machine learning : machinelearning we tried something like this here with the /r/mlpapers sub-reddit , but that eventually fell through due to a lack of participation . if we were to try something like it again , i would be willing to participate . EOQ make it happen EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ nvidia has some videos out for demoing stuff . also , honda research is doing some stuff , but not quite self driving : misu, teruhisa , et al . situated language understanding at NUM miles per hour.?15th annual meeting of the special interest group on discourse and dialogue . NUM EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ thanks a lot ! EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ there are lot of different challenges and pieces that come together to make self-driving cars work : perception, controls , path planning and different teams take different approaches to each of these , but perhaps i can give a somewhat dated overview . most self-driving cars use a mixture of lidar and cameras for their perception stack . some of the necessary perception tasks include obstacle detection , localization, multi-target tracking , and object detection/classification . for anyone of these heuristic-based or machine learning-based solutions may be applied . for instance for obstacle detection , you can get a lot of the way their by simply noticing what is significantly above the ground plane . a non deep learning stack for this would look like : obstacle detection via totem algorithm localization via slam algorithm multi-target tracking via kalman filters object-detection via sift and svm's deep learning could in theory be used to replace any of these setups and is definitely trending upwards . an impediment has been getting deep learning to work well with sparse NUM d pointclouds . ( some teams have taken the approach of migrating off of lidar , other have invested into research in this area ) . deep learning or deep reinforcement learning could also have uses in controls and path planning aspects of self-driving cars as well . admittedly my info may be a bit dated , but hopefully this is helpful . EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ how would a beginner go about learning this stuff ? EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ look for review papers here's a decent starting place . URL EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ there is a course called self driving cars in udacity . EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ i am not an expert on self-driving cars , so take this with a grain of salt : self-driving car is at heart a computer vision problem-computer must be able to recognize what it is seeing ( as in what's road , what's a sidewalk , what's a traffic light ) and then evaluate the situation . deep learning are complex neural networks ( witch a few tweaks ) that are very good at looking at an image and creating internal representations that make sense for the compute out of these images . in the end you need to be able for the computer to see road edges , other cars and road signs . i do not know how the other part works-translating the images understood by computer into action , but traffic is a set of formal and informal rules which then need to go into a prediction of what the car should do ( accelerate , brake, turn ) ... and is probably the easier part . these rules are probably a trained classification algorithm on some data from both a test track and perhaps even collected from real drivers . plugging a gps system that plans the route is compared to all this a trivial problem . EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ it doesn't need to know the traffic rules if you give it a training set that captures all the relevant situations . also, if you feed in the human action it can learn to imitate even the driving style of its instructor . EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ yeah you could definitely let it learn from the training set . as i've said i am not an expert on self driving cars , but the question is-if some rules are set in stone and you could easily translate them to some logical rules for a machine , why would you use an algorithm to learn them ? it would be inefficient . an example would be-computer vision identifies a traffic sign giving you the max speed . why wouldn't you let the car change speed based on the number it sees on a sign rather than letting it figure out it should slow down to that speed ? EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ maybe in that one case it would be simpler , but on a general case interactions are complex and hard to define in code , so it's easier to just record NUM s of humans driving by millions of traffic signs and their reactions . then a reinforcement learning algorithm will devise a policy that provably works best in all the situations recorded in the database instead of just dictating an abstract rule without considering all the other interferences that might appear . consider learning to react to a person walking into the road . how would you detect the person and its intent without machine learning ? it's very hard . a person has many possible forms . so we leave that to the neural nets . the same happens with driving strategies-they are much more complex in reality than on paper and we can't simply code them with if's and hand written rules . EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ but i am not arguing against ml being used to handle situations , i've said the following in my original post : these rules are probably a trained classification algorithm on some data from both a test track and perhaps even collected from real drivers . i have possibly forgotten i have written that :). my assumption was that the classifier used creates its internal representation of the rules based on the input variables which is the same as you are saying . you definitely wouldn't write the whole thing with if statements , we are far behind that paradigm . so i agree with you , i was just wondering whether there still aren't some ifs . a good example on combining ifs and ml algorithms is this one case where a guy had to predict when a bed becomes free in a hospital which can happen in NUM ways-a patient dies or gets well enough to leave the hospital . now, if you use patient inputs ( vital signs , etc. ) the algorithm might get confusing messages-some patient get better and leave while others get worse . if you would split the problem into NUM predictions-predicting people getting worse and predicting people getting better and then ensemble it , you might get a much better result as opposed to relying on a ml algorithm taking care of that split . i have also encountered something similar in a prediction problem i was solving at work recently where we were able to improve all relevant metrics , by doing an if clause that excludes part of the data from the prediction and marks them as negatives right away . EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ i saw a talk by google at mit and while they did not show any code ( that got a groan : ) there were many video examples of situations . the visualization was NUM d bounding boxes on a line drawing image of the upcoming intersection . so it was consolidating the gps and map database data with real time visual imaging and lidar laser ranging information . the speaker was specific that while they were doing daily builds of to improve the model there was no live ml occurring in the vehicles . lots of data from each days interaction used to improve the model and tests of the model but it was locked code in the car . EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ sounds cool , could you link to the video ? EOA 
 what is the technology stack behind a self driving car ? i keep hearing deep learning come up , can someone explain ? : machinelearning lol at the last line even though i wasn't specifically asking about google cars :p know where i can look for further reading ? EOQ i guess it might be this video : URL EOA 
 question about reinforcement learning application in business : machinelearning lets assume it can be formulated as an rl problem . so, the agent is the brand , environment is the users on twitter ( following the brand ) . actions involve which tweet to pick from a pool of tweets ?. an important question to consider whether maximizing long term return ( sum of discounted rewards ) makes sense . one bad tweet could be potentially disastrous . it is also not clear why maximizing immediate rewards per tweet is a bad idea . in this case , you can learn features/context from tweets that produce high reward . this can be done in offline/online setting . also, if tweets are treated as independent , then there's no need for solving it using rl . even if they aren't , you can still dependencies without using rl . EOQ good point about the long-term return . i will have to think more about that . indeed maximizing immediate rewards can be critical for many brands . the long-term reward could be the total followers . but i don't know whether that will work here . i think the dependencies are important between tweets because that's how ( good ) social media marketing teams learn and decide on the content to share . when you said i can still model dependencies without rl , you meant using ml or more parametric models ? for example , i can use vector autoregression for this problem . EOA 
 question about reinforcement learning application in business : machinelearning lets assume it can be formulated as an rl problem . so, the agent is the brand , environment is the users on twitter ( following the brand ) . actions involve which tweet to pick from a pool of tweets ?. an important question to consider whether maximizing long term return ( sum of discounted rewards ) makes sense . one bad tweet could be potentially disastrous . it is also not clear why maximizing immediate rewards per tweet is a bad idea . in this case , you can learn features/context from tweets that produce high reward . this can be done in offline/online setting . also, if tweets are treated as independent , then there's no need for solving it using rl . even if they aren't , you can still dependencies without using rl . EOQ if your objective is to just predict the success of a tweet , then why not just regress the likes based on some deep/shallow features of tweet text ? i don't know much about rl , but what you are proposing could be of use of you want to lead a publicity campaign and learn optional campaigns or something like that . EOA 
 question about reinforcement learning application in business : machinelearning lets assume it can be formulated as an rl problem . so, the agent is the brand , environment is the users on twitter ( following the brand ) . actions involve which tweet to pick from a pool of tweets ?. an important question to consider whether maximizing long term return ( sum of discounted rewards ) makes sense . one bad tweet could be potentially disastrous . it is also not clear why maximizing immediate rewards per tweet is a bad idea . in this case , you can learn features/context from tweets that produce high reward . this can be done in offline/online setting . also, if tweets are treated as independent , then there's no need for solving it using rl . even if they aren't , you can still dependencies without using rl . EOQ well my objective is to see whether rl would be a good candidate to model this behavior . EOA 
 question about reinforcement learning application in business : machinelearning lets assume it can be formulated as an rl problem . so, the agent is the brand , environment is the users on twitter ( following the brand ) . actions involve which tweet to pick from a pool of tweets ?. an important question to consider whether maximizing long term return ( sum of discounted rewards ) makes sense . one bad tweet could be potentially disastrous . it is also not clear why maximizing immediate rewards per tweet is a bad idea . in this case , you can learn features/context from tweets that produce high reward . this can be done in offline/online setting . also, if tweets are treated as independent , then there's no need for solving it using rl . even if they aren't , you can still dependencies without using rl . EOQ the central problem of rl is the exploration-exploitation tradeoff : when do i stop learning and start doing ? how do i maximize benefit given a resource budget ? to learn how to make good tweets , you need to experiment with many techniques . after some time , you can do some statistical hypothesis testing or supervised learning to estimate a model for making tweets . you may use that model for a while , but after some time you might wonder if the model is still valid . unfortunately , your latest data , after you started doing what the model indicated was best , is a biased sample not suitable for supervised learning . if you are nervous , you might start experimenting with other techniques again , techniques that your model suggests are non-optimal . now you're doing reinforcement learning . EOA 
  EOA 
